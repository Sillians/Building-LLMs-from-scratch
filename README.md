# Building-LLMs-from-scratch

This repository provides a practical guide to building a `GPT-style` Large Language Model (LLM) from the ground up using PyTorch, following the structure of Sebastian Raschka's book, Build a Large Language Model (From Scratch).

### Prerequisites
- Python 3.8+
- PyTorch
- NumPy
- Matplotlib
- JupyterLab or Notebooks
- Calculus
- Matrix (Vectors and Matrix Computation)
- Differentiation
- Hugging Face libraries: `transformers`, `datasets`, `huggingface_hub`
- `gradio` for deployment
