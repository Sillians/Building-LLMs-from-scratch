{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a578d4c",
   "metadata": {},
   "source": [
    "# Working with Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8677d4a5",
   "metadata": {},
   "source": [
    "During the pretraining stage, LLMs process text one word at a time. Training LLMs with millions to billions of parameters using a next-word prediction task yields models with impressive capabilities. These models can then be further finetuned to follow general instructions or perform specific target tasks.\n",
    "\n",
    "![Alt text](../../assests/working-with-data.png)\n",
    "\n",
    "In this section, we'll learn how to prepare input text for training LLMs. This involves splitting text into individual word and subword tokens, which can then be encoded into vector representations for the LLM. \n",
    "\n",
    "We'll also learn about advanced tokenization schemes like byte pair encoding, which is utilized in popular LLMs like `GPT`. \n",
    "\n",
    "Lastly, we'll implement a sampling and data loading strategy to produce the input-output pairs necessary for training LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07111ca",
   "metadata": {},
   "source": [
    "## Understanding word embeddings\n",
    "\n",
    "Deep neural network models, including LLMs, cannot process raw text directly. Since text is categorical, it isn't compatible with the mathematical operations used to implement and train neural networks. Therefore, we need a way to represent words as continuous-valued vectors.\n",
    "\n",
    "The concept of converting data into a vector format is often referred to as `embedding`. Using a specific neural network layer or another pretrained neural network model, we can embed different data types, for example, `video`, `audio`, and `text`.\n",
    "\n",
    "![Alt text](../../assests/Data-embedding.png)\n",
    "\n",
    "We can process various different data formats via `embedding models`. However, it's important to note that different data formats require distinct embedding models. For example, an embedding model designed for text would not be suitable for embedding audio or video data.\n",
    "\n",
    "At its core, an embedding is a mapping from `discrete objects`, such as words, images, or even entire documents, to points in a `continuous vector space` -- the primary purpose of embeddings is to convert non-numeric data into a format that neural networks can process.\n",
    "\n",
    "While `word embeddings` are the most common form of text embedding, there are also embeddings for sentences, paragraphs, or whole documents. Sentence or paragraph embeddings are popular choices for `retrieval-augmented generation`. Retrieval-augmented generation combines generation (like producing text) with retrieval (like searching an\n",
    "external knowledge base) to pull relevant information when generating text.\n",
    "\n",
    "There are several algorithms and frameworks that have been developed to generate word embeddings. One of the earlier and most popular examples is the `Word2Vec` approach. `Word2Vec` trained neural network architecture to generate word embeddings by predicting the context of a word given the target word or vice versa. The main idea behind Word2Vec is that words that appear in similar contexts tend to have similar meanings. Consequently, when projected into `2-dimensional` word embeddings for visualization purposes, it can be seen that similar terms cluster together, as shown below;\n",
    "\n",
    "![Alt text](../../assests/embeddings.png)\n",
    "\n",
    "Word embeddings can have varying dimensions, from one to thousands. We can choose two-dimensional word embeddings for visualization purposes. A higher dimensionality might capture more nuanced relationships but at the cost of computational\n",
    "efficiency.\n",
    "\n",
    "While we can use pretrained models such as `Word2Vec` to generate embeddings for machine learning models, LLMs commonly produce their own embeddings that are part of the input layer and are updated during training. The advantage of optimizing the embeddings as part of the LLM training instead of using Word2Vec is that the embeddings are optimized to the specific task and data at hand. We will implement such embedding layers later in this section. Furthermore, LLMs can also create contextualized output embeddings.\n",
    "\n",
    "The steps for preparing the embeddings used by an LLM, includes splitting text into words, converting words into tokens, and turning tokens into embedding vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3650dfba",
   "metadata": {},
   "source": [
    "**Embeddings**\n",
    "\n",
    "Embeddings are low-dimensional numerical vector representations of real-world objects like text, images, or audio that capture their semantic meaning and relationships. By converting complex, non-numeric data into this mathematical format, embeddings enable machine learning and AI models to process and understand these objects, allowing for tasks such as identifying similar items, classifying data, and powering search and recommendation systems.\n",
    "\n",
    "**What Embeddings Do**\n",
    "\n",
    "- `Represent Data Numerically:` Embeddings translate non-numeric data into lists of numbers (vectors) that computers can understand. \n",
    "\n",
    "- `Preserve Meaning and Relationships:` The geometric distances between these vectors in a multi-dimensional space reflect the semantic similarity or dissimilarity of the original data objects. \n",
    "\n",
    "- `Provide Compact Representations:` They are a form of lossy compression, creating smaller, more efficient representations of complex data while retaining essential properties. \n",
    "\n",
    "\n",
    "**How Embeddings Are Used**\n",
    "\n",
    "- `Semantic Search:` Finding documents or images that are semantically similar to a query, rather than just keyword matches. \n",
    "\n",
    "- `Clustering and Classification:` Grouping similar items or assigning them to predefined categories. \n",
    "  \n",
    "- `Retrieval-Augmented Generation (RAG):` Enhancing the accuracy and relevance of responses from large language models by providing relevant context retrieved through embeddings. \n",
    "\n",
    "- `Duplicate Detection:` Identifying duplicate or near-duplicate content by comparing their vector representations. \n",
    "\n",
    "- `Code Analytics:` Performing semantic searches on code repositories and analyzing code structure.\n",
    "\n",
    "\n",
    "**Examples of Embeddings**\n",
    "\n",
    "- `Word Embeddings:` Convert words into vectors, where words with similar meanings (e.g., \"dog\" and \"cat\") are located closer together in the vector space.\n",
    "\n",
    "- `Image Embeddings:` Represent images as vectors, allowing for the comparison of visual content.\n",
    "\n",
    "- `Audio Embeddings:` Convert audio signals into numerical representations for processing and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e1696",
   "metadata": {},
   "source": [
    "## Tokenizing text\n",
    "\n",
    "This section covers how we split input text into individual tokens, a required preprocessing step for creating embeddings for an LLM. These tokens are either individual words or special characters, inclduing punctuation characters. \n",
    "\n",
    "![Alt text](../../assests/tokens.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8df28f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.0.1\n",
      "tiktoken version: 0.11.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce9c4a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "# Reading in a short story as text sample into Python\n",
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50b52992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me \n"
     ]
    }
   ],
   "source": [
    "print(raw_text[:120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a3ee880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
     ]
    }
   ],
   "source": [
    "# Split a text on whitespace characters\n",
    "import re\n",
    "\n",
    "text = \"Hello, world. This, is a test.\"\n",
    "result = re.split(r'(\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642267e0",
   "metadata": {},
   "source": [
    "Note that the simple tokenization scheme mostly works for separating the example text into individual words, however, some words are still connected to punctuation characters that we want to have as separate list entries. We also refrain from making all text lowercase because capitalization helps LLMs distinguish between proper nouns and common nouns, understand sentence structure, and learn to generate text with proper capitalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed69b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
     ]
    }
   ],
   "source": [
    "# We don't only want to split on whitespaces but also commas and periods, \n",
    "# so let's modify the regular expression to do that as well\n",
    "\n",
    "result = re.split(r'([,.]|\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf0cd2",
   "metadata": {},
   "source": [
    "A small remaining issue is that the list still includes whitespace characters. Optionally, we can remove these redundant characters safely as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc59368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
     ]
    }
   ],
   "source": [
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "061798d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "# strip() Removes leading and trailing characters from a string. By default, it removes whitespace characters (spaces, tabs, newlines).\n",
    "\n",
    "text = \"   Hello World!   \"\n",
    "cleaned_text = text.strip()\n",
    "print(cleaned_text) # Output: \"Hello World!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cdd897",
   "metadata": {},
   "source": [
    "**REMOVING WHITESPACES OR NOT**\n",
    "\n",
    "When developing a simple tokenizer, whether we should encode whitespaces as separate characters or just remove them depends on our application and its requirements. Removing whitespaces reduces the memory and computing requirements. However, keeping whitespaces can be useful if we train models that are sensitive to the exact structure of the text (for example, Python code, which is sensitive to indentation and spacing). Here, we remove whitespaces for simplicity and brevity of the tokenized outputs. Later, we will switch to a tokenization scheme that includes whitespaces."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194fd8cf",
   "metadata": {},
   "source": [
    "The tokenization scheme we devised above works well on the simple sample text. Let's modify it a bit further so that it can also handle other types of punctuation, such as `question marks`, `quotation marks`, and the `double-dashes` we have seen earlier in the first 100 characters of Edith Wharton's short story, along with additional special characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb722257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'text', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. Is this-- a text?\"\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7299b99",
   "metadata": {},
   "source": [
    "This is pretty good, and we are not ready to apply this tokenization to the raw text.\n",
    "\n",
    "Now that we got a basic tokenizer working, let's apply it to Edith Wharton's entire short story:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa51e420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(len(preprocessed))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "387a8832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'HAD',\n",
       " 'always',\n",
       " 'thought',\n",
       " 'Jack',\n",
       " 'Gisburn',\n",
       " 'rather',\n",
       " 'a',\n",
       " 'cheap',\n",
       " 'genius',\n",
       " '--',\n",
       " 'though',\n",
       " 'a',\n",
       " 'good',\n",
       " 'fellow',\n",
       " 'enough',\n",
       " '--',\n",
       " 'so',\n",
       " 'it',\n",
       " 'was',\n",
       " 'no',\n",
       " 'great',\n",
       " 'surprise',\n",
       " 'to',\n",
       " 'me',\n",
       " 'to',\n",
       " 'hear',\n",
       " 'that',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'height',\n",
       " 'of',\n",
       " 'his',\n",
       " 'glory',\n",
       " ',',\n",
       " 'he',\n",
       " 'had',\n",
       " 'dropped',\n",
       " 'his',\n",
       " 'painting',\n",
       " ',',\n",
       " 'married',\n",
       " 'a',\n",
       " 'rich',\n",
       " 'widow',\n",
       " ',',\n",
       " 'and',\n",
       " 'established',\n",
       " 'himself',\n",
       " 'in',\n",
       " 'a',\n",
       " 'villa',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Riviera',\n",
       " '.',\n",
       " '(',\n",
       " 'Though',\n",
       " 'I',\n",
       " 'rather',\n",
       " 'thought',\n",
       " 'it',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'Rome',\n",
       " 'or',\n",
       " 'Florence',\n",
       " '.',\n",
       " ')',\n",
       " '\"',\n",
       " 'The',\n",
       " 'height',\n",
       " 'of',\n",
       " 'his',\n",
       " 'glory',\n",
       " '\"',\n",
       " '--',\n",
       " 'that',\n",
       " 'was',\n",
       " 'what',\n",
       " 'the',\n",
       " 'women',\n",
       " 'called',\n",
       " 'it',\n",
       " '.',\n",
       " 'I',\n",
       " 'can',\n",
       " 'hear',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gideon',\n",
       " 'Thwing',\n",
       " '--',\n",
       " 'his',\n",
       " 'last',\n",
       " 'Chicago',\n",
       " 'sitter',\n",
       " '--',\n",
       " 'deploring',\n",
       " 'his',\n",
       " 'unaccountable',\n",
       " 'abdication',\n",
       " '.',\n",
       " '\"',\n",
       " 'Of',\n",
       " 'course',\n",
       " 'it',\n",
       " \"'\",\n",
       " 's',\n",
       " 'going',\n",
       " 'to',\n",
       " 'send',\n",
       " 'the',\n",
       " 'value',\n",
       " 'of',\n",
       " 'my',\n",
       " 'picture',\n",
       " \"'\",\n",
       " 'way',\n",
       " 'up',\n",
       " ';',\n",
       " 'but',\n",
       " 'I',\n",
       " 'don',\n",
       " \"'\",\n",
       " 't',\n",
       " 'think',\n",
       " 'of',\n",
       " 'that',\n",
       " ',',\n",
       " 'Mr',\n",
       " '.',\n",
       " 'Rickham',\n",
       " '--',\n",
       " 'the',\n",
       " 'loss',\n",
       " 'to',\n",
       " 'Arrt',\n",
       " 'is',\n",
       " 'all',\n",
       " 'I',\n",
       " 'think',\n",
       " 'of',\n",
       " '.',\n",
       " '\"',\n",
       " 'The',\n",
       " 'word',\n",
       " ',',\n",
       " 'on',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Thwing',\n",
       " \"'\",\n",
       " 's',\n",
       " 'lips',\n",
       " ',',\n",
       " 'multiplied',\n",
       " 'its',\n",
       " '_',\n",
       " 'rs',\n",
       " '_',\n",
       " 'as',\n",
       " 'though',\n",
       " 'they',\n",
       " 'were',\n",
       " 'reflected',\n",
       " 'in',\n",
       " 'an',\n",
       " 'endless',\n",
       " 'vista',\n",
       " 'of',\n",
       " 'mirrors',\n",
       " '.',\n",
       " 'And',\n",
       " 'it',\n",
       " 'was',\n",
       " 'not',\n",
       " 'only',\n",
       " 'the',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Thwings',\n",
       " 'who',\n",
       " 'mourned',\n",
       " '.',\n",
       " 'Had',\n",
       " 'not',\n",
       " 'the',\n",
       " 'exquisite',\n",
       " 'Hermia',\n",
       " 'Croft',\n",
       " ',',\n",
       " 'at',\n",
       " 'the',\n",
       " 'last',\n",
       " 'Grafton',\n",
       " 'Gallery',\n",
       " 'show',\n",
       " ',',\n",
       " 'stopped',\n",
       " 'me',\n",
       " 'before',\n",
       " 'Gisburn',\n",
       " \"'\",\n",
       " 's',\n",
       " '\"',\n",
       " 'Moon-dancers',\n",
       " '\"',\n",
       " 'to',\n",
       " 'say',\n",
       " ',',\n",
       " 'with',\n",
       " 'tears',\n",
       " 'in',\n",
       " 'her',\n",
       " 'eyes',\n",
       " ':',\n",
       " '\"',\n",
       " 'We',\n",
       " 'shall',\n",
       " 'not',\n",
       " 'look',\n",
       " 'upon',\n",
       " 'its',\n",
       " 'like',\n",
       " 'again',\n",
       " '\"',\n",
       " '?',\n",
       " 'Well',\n",
       " '!',\n",
       " '--',\n",
       " 'even',\n",
       " 'through',\n",
       " 'the',\n",
       " 'prism',\n",
       " 'of',\n",
       " 'Hermia',\n",
       " \"'\",\n",
       " 's',\n",
       " 'tears',\n",
       " 'I',\n",
       " 'felt',\n",
       " 'able',\n",
       " 'to',\n",
       " 'face',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'with',\n",
       " 'equanimity',\n",
       " '.',\n",
       " 'Poor',\n",
       " 'Jack',\n",
       " 'Gisburn',\n",
       " '!',\n",
       " 'The',\n",
       " 'women',\n",
       " 'had',\n",
       " 'made',\n",
       " 'him',\n",
       " '--',\n",
       " 'it',\n",
       " 'was',\n",
       " 'fitting',\n",
       " 'that',\n",
       " 'they',\n",
       " 'should',\n",
       " 'mourn',\n",
       " 'him',\n",
       " '.',\n",
       " 'Among',\n",
       " 'his',\n",
       " 'own',\n",
       " 'sex',\n",
       " 'fewer',\n",
       " 'regrets',\n",
       " 'were',\n",
       " 'heard',\n",
       " ',',\n",
       " 'and',\n",
       " 'in',\n",
       " 'his',\n",
       " 'own',\n",
       " 'trade',\n",
       " 'hardly',\n",
       " 'a',\n",
       " 'murmur',\n",
       " '.',\n",
       " 'Professional',\n",
       " 'jealousy',\n",
       " '?',\n",
       " 'Perhaps',\n",
       " '.',\n",
       " 'If',\n",
       " 'it',\n",
       " 'were',\n",
       " ',',\n",
       " 'the',\n",
       " 'honour',\n",
       " 'of',\n",
       " 'the',\n",
       " 'craft',\n",
       " 'was',\n",
       " 'vindicated',\n",
       " 'by',\n",
       " 'little',\n",
       " 'Claude',\n",
       " 'Nutley',\n",
       " ',',\n",
       " 'who',\n",
       " ',',\n",
       " 'in',\n",
       " 'all',\n",
       " 'good',\n",
       " 'faith',\n",
       " ',',\n",
       " 'brought',\n",
       " 'out',\n",
       " 'in',\n",
       " 'the',\n",
       " 'Burlington',\n",
       " 'a',\n",
       " 'very',\n",
       " 'handsome',\n",
       " '\"',\n",
       " 'obituary',\n",
       " '\"',\n",
       " 'on',\n",
       " 'Jack',\n",
       " '--',\n",
       " 'one',\n",
       " 'of',\n",
       " 'those',\n",
       " 'showy',\n",
       " 'articles',\n",
       " 'stocked',\n",
       " 'with',\n",
       " 'random',\n",
       " 'technicalities',\n",
       " 'that',\n",
       " 'I',\n",
       " 'have',\n",
       " 'heard',\n",
       " '(',\n",
       " 'I',\n",
       " 'won',\n",
       " \"'\",\n",
       " 't',\n",
       " 'say',\n",
       " 'by',\n",
       " 'whom',\n",
       " ')',\n",
       " 'compared',\n",
       " 'to',\n",
       " 'Gisburn',\n",
       " \"'\",\n",
       " 's',\n",
       " 'painting',\n",
       " '.',\n",
       " 'And',\n",
       " 'so',\n",
       " '--',\n",
       " 'his',\n",
       " 'resolve',\n",
       " 'being',\n",
       " 'apparently',\n",
       " 'irrevocable',\n",
       " '--',\n",
       " 'the',\n",
       " 'discussion',\n",
       " 'gradually',\n",
       " 'died',\n",
       " 'out',\n",
       " ',',\n",
       " 'and',\n",
       " ',',\n",
       " 'as',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Thwing',\n",
       " 'had',\n",
       " 'predicted',\n",
       " ',',\n",
       " 'the',\n",
       " 'price',\n",
       " 'of',\n",
       " '\"',\n",
       " 'Gisburns',\n",
       " '\"',\n",
       " 'went',\n",
       " 'up',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'not',\n",
       " 'till',\n",
       " 'three',\n",
       " 'years',\n",
       " 'later',\n",
       " 'that',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'course',\n",
       " 'of',\n",
       " 'a',\n",
       " 'few',\n",
       " 'weeks',\n",
       " \"'\",\n",
       " 'idling',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Riviera',\n",
       " ',',\n",
       " 'it',\n",
       " 'suddenly',\n",
       " 'occurred',\n",
       " 'to',\n",
       " 'me',\n",
       " 'to',\n",
       " 'wonder',\n",
       " 'why',\n",
       " 'Gisburn',\n",
       " 'had',\n",
       " 'given',\n",
       " 'up',\n",
       " 'his',\n",
       " 'painting',\n",
       " '.',\n",
       " 'On',\n",
       " 'reflection',\n",
       " ',',\n",
       " 'it',\n",
       " 'really',\n",
       " 'was',\n",
       " 'a',\n",
       " 'tempting',\n",
       " 'problem',\n",
       " '.',\n",
       " 'To',\n",
       " 'accuse',\n",
       " 'his',\n",
       " 'wife',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'too',\n",
       " 'easy',\n",
       " '--',\n",
       " 'his',\n",
       " 'fair',\n",
       " 'sitters',\n",
       " 'had',\n",
       " 'been',\n",
       " 'denied',\n",
       " 'the',\n",
       " 'solace',\n",
       " 'of',\n",
       " 'saying',\n",
       " 'that',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " 'had',\n",
       " '\"',\n",
       " 'dragged',\n",
       " 'him',\n",
       " 'down',\n",
       " '.',\n",
       " '\"',\n",
       " 'For',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " '--',\n",
       " 'as',\n",
       " 'such',\n",
       " '--',\n",
       " 'had',\n",
       " 'not',\n",
       " 'existed',\n",
       " 'till',\n",
       " 'nearly',\n",
       " 'a',\n",
       " 'year',\n",
       " 'after',\n",
       " 'Jack',\n",
       " \"'\",\n",
       " 's',\n",
       " 'resolve',\n",
       " 'had',\n",
       " 'been',\n",
       " 'taken',\n",
       " '.',\n",
       " 'It',\n",
       " 'might',\n",
       " 'be',\n",
       " 'that',\n",
       " 'he',\n",
       " 'had',\n",
       " 'married',\n",
       " 'her',\n",
       " '--',\n",
       " 'since',\n",
       " 'he',\n",
       " 'liked',\n",
       " 'his',\n",
       " 'ease',\n",
       " '--',\n",
       " 'because',\n",
       " 'he',\n",
       " 'didn',\n",
       " \"'\",\n",
       " 't',\n",
       " 'want',\n",
       " 'to',\n",
       " 'go',\n",
       " 'on',\n",
       " 'painting',\n",
       " ';',\n",
       " 'but',\n",
       " 'it',\n",
       " 'would',\n",
       " 'have',\n",
       " 'been',\n",
       " 'hard',\n",
       " 'to',\n",
       " 'prove',\n",
       " 'that',\n",
       " 'he',\n",
       " 'had',\n",
       " 'given',\n",
       " 'up',\n",
       " 'his',\n",
       " 'painting',\n",
       " 'because',\n",
       " 'he',\n",
       " 'had',\n",
       " 'married',\n",
       " 'her',\n",
       " '.',\n",
       " 'Of',\n",
       " 'course',\n",
       " ',',\n",
       " 'if',\n",
       " 'she',\n",
       " 'had',\n",
       " 'not',\n",
       " 'dragged',\n",
       " 'him',\n",
       " 'down',\n",
       " ',',\n",
       " 'she',\n",
       " 'had',\n",
       " 'equally',\n",
       " ',',\n",
       " 'as',\n",
       " 'Miss',\n",
       " 'Croft',\n",
       " 'contended',\n",
       " ',',\n",
       " 'failed',\n",
       " 'to',\n",
       " '\"',\n",
       " 'lift',\n",
       " 'him',\n",
       " 'up',\n",
       " '\"',\n",
       " '--',\n",
       " 'she',\n",
       " 'had',\n",
       " 'not',\n",
       " 'led',\n",
       " 'him',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'easel',\n",
       " '.',\n",
       " 'To',\n",
       " 'put',\n",
       " 'the',\n",
       " 'brush',\n",
       " 'into',\n",
       " 'his',\n",
       " 'hand',\n",
       " 'again',\n",
       " '--',\n",
       " 'what',\n",
       " 'a',\n",
       " 'vocation',\n",
       " 'for',\n",
       " 'a',\n",
       " 'wife',\n",
       " '!',\n",
       " 'But',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " 'appeared',\n",
       " 'to',\n",
       " 'have',\n",
       " 'disdained',\n",
       " 'it',\n",
       " '--',\n",
       " 'and',\n",
       " 'I',\n",
       " 'felt',\n",
       " 'it',\n",
       " 'might',\n",
       " 'be',\n",
       " 'interesting',\n",
       " 'to',\n",
       " 'find',\n",
       " 'out',\n",
       " 'why',\n",
       " '.',\n",
       " 'The',\n",
       " 'desultory',\n",
       " 'life',\n",
       " 'of',\n",
       " 'the',\n",
       " 'Riviera',\n",
       " 'lends',\n",
       " 'itself',\n",
       " 'to',\n",
       " 'such',\n",
       " 'purely',\n",
       " 'academic',\n",
       " 'speculations',\n",
       " ';',\n",
       " 'and',\n",
       " 'having',\n",
       " ',',\n",
       " 'on',\n",
       " 'my',\n",
       " 'way',\n",
       " 'to',\n",
       " 'Monte',\n",
       " 'Carlo',\n",
       " ',',\n",
       " 'caught',\n",
       " 'a',\n",
       " 'glimpse',\n",
       " 'of',\n",
       " 'Jack',\n",
       " \"'\",\n",
       " 's',\n",
       " 'balustraded',\n",
       " 'terraces',\n",
       " 'between',\n",
       " 'the',\n",
       " 'pines',\n",
       " ',',\n",
       " 'I',\n",
       " 'had',\n",
       " 'myself',\n",
       " 'borne',\n",
       " 'thither',\n",
       " 'the',\n",
       " 'next',\n",
       " 'day',\n",
       " '.',\n",
       " 'I',\n",
       " 'found',\n",
       " 'the',\n",
       " 'couple',\n",
       " 'at',\n",
       " 'tea',\n",
       " 'beneath',\n",
       " 'their',\n",
       " 'palm-trees',\n",
       " ';',\n",
       " 'and',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " \"'\",\n",
       " 's',\n",
       " 'welcome',\n",
       " 'was',\n",
       " 'so',\n",
       " 'genial',\n",
       " 'that',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'ensuing',\n",
       " 'weeks',\n",
       " ',',\n",
       " 'I',\n",
       " 'claimed',\n",
       " 'it',\n",
       " 'frequently',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'not',\n",
       " 'that',\n",
       " 'my',\n",
       " 'hostess',\n",
       " 'was',\n",
       " '\"',\n",
       " 'interesting',\n",
       " '\"',\n",
       " ':',\n",
       " 'on',\n",
       " 'that',\n",
       " 'point',\n",
       " 'I',\n",
       " 'could',\n",
       " 'have',\n",
       " 'given',\n",
       " 'Miss',\n",
       " 'Croft',\n",
       " 'the',\n",
       " 'fullest',\n",
       " 'reassurance',\n",
       " '.',\n",
       " 'It',\n",
       " 'was',\n",
       " 'just',\n",
       " 'because',\n",
       " 'she',\n",
       " 'was',\n",
       " '_',\n",
       " 'not',\n",
       " '_',\n",
       " 'interesting',\n",
       " '--',\n",
       " 'if',\n",
       " 'I',\n",
       " 'may',\n",
       " 'be',\n",
       " 'pardoned',\n",
       " 'the',\n",
       " 'bull',\n",
       " '--',\n",
       " 'that',\n",
       " 'I',\n",
       " 'found',\n",
       " 'her',\n",
       " 'so',\n",
       " '.',\n",
       " 'For',\n",
       " 'Jack',\n",
       " ',',\n",
       " 'all',\n",
       " 'his',\n",
       " 'life',\n",
       " ',',\n",
       " 'had',\n",
       " 'been',\n",
       " 'surrounded',\n",
       " 'by',\n",
       " 'interesting',\n",
       " 'women',\n",
       " ':',\n",
       " 'they',\n",
       " 'had',\n",
       " 'fostered',\n",
       " 'his',\n",
       " 'art',\n",
       " ',',\n",
       " 'it',\n",
       " 'had',\n",
       " 'been',\n",
       " 'reared',\n",
       " 'in',\n",
       " 'the',\n",
       " 'hot-house',\n",
       " 'of',\n",
       " 'their',\n",
       " 'adulation',\n",
       " '.',\n",
       " 'And',\n",
       " 'it',\n",
       " 'was',\n",
       " 'therefore',\n",
       " 'instructive',\n",
       " 'to',\n",
       " 'note',\n",
       " 'what',\n",
       " 'effect',\n",
       " 'the',\n",
       " '\"',\n",
       " 'deadening',\n",
       " 'atmosphere',\n",
       " 'of',\n",
       " 'mediocrity',\n",
       " '\"',\n",
       " '(',\n",
       " 'I',\n",
       " 'quote',\n",
       " 'Miss',\n",
       " 'Croft',\n",
       " ')',\n",
       " 'was',\n",
       " 'having',\n",
       " 'on',\n",
       " 'him',\n",
       " '.',\n",
       " 'I',\n",
       " 'have',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " 'was',\n",
       " 'rich',\n",
       " ';',\n",
       " 'and',\n",
       " 'it',\n",
       " 'was',\n",
       " 'immediately',\n",
       " 'perceptible',\n",
       " 'that',\n",
       " 'her',\n",
       " 'husband',\n",
       " 'was',\n",
       " 'extracting',\n",
       " 'from',\n",
       " 'this',\n",
       " 'circumstance',\n",
       " 'a',\n",
       " 'delicate',\n",
       " 'but',\n",
       " 'substantial',\n",
       " 'satisfaction',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " ',',\n",
       " 'as',\n",
       " 'a',\n",
       " 'rule',\n",
       " ',',\n",
       " 'the',\n",
       " 'people',\n",
       " 'who',\n",
       " 'scorn',\n",
       " 'money',\n",
       " 'who',\n",
       " 'get',\n",
       " 'most',\n",
       " 'out',\n",
       " 'of',\n",
       " 'it',\n",
       " ';',\n",
       " 'and',\n",
       " 'Jack',\n",
       " \"'\",\n",
       " 's',\n",
       " 'elegant',\n",
       " 'disdain',\n",
       " 'of',\n",
       " 'his',\n",
       " 'wife',\n",
       " \"'\",\n",
       " 's',\n",
       " 'big',\n",
       " 'balance',\n",
       " 'enabled',\n",
       " 'him',\n",
       " ',',\n",
       " 'with',\n",
       " 'an',\n",
       " 'appearance',\n",
       " 'of',\n",
       " 'perfect',\n",
       " 'good-breeding',\n",
       " ',',\n",
       " 'to',\n",
       " 'transmute',\n",
       " 'it',\n",
       " 'into',\n",
       " 'objects',\n",
       " 'of',\n",
       " 'art',\n",
       " 'and',\n",
       " 'luxury',\n",
       " '.',\n",
       " 'To',\n",
       " 'the',\n",
       " 'latter',\n",
       " ',',\n",
       " 'I',\n",
       " 'must',\n",
       " 'add',\n",
       " ',',\n",
       " 'he',\n",
       " 'remained',\n",
       " 'relatively',\n",
       " 'indifferent',\n",
       " ';',\n",
       " 'but',\n",
       " 'he',\n",
       " 'was',\n",
       " 'buying',\n",
       " 'Renaissance',\n",
       " 'bronzes',\n",
       " 'and',\n",
       " 'eighteenth-century',\n",
       " 'pictures',\n",
       " 'with',\n",
       " 'a',\n",
       " 'discrimination',\n",
       " 'that',\n",
       " 'bespoke',\n",
       " 'the',\n",
       " 'amplest',\n",
       " 'resources',\n",
       " '.',\n",
       " '\"',\n",
       " 'Money',\n",
       " \"'\",\n",
       " 's',\n",
       " 'only',\n",
       " 'excuse',\n",
       " 'is',\n",
       " 'to',\n",
       " 'put',\n",
       " 'beauty',\n",
       " 'into',\n",
       " 'circulation',\n",
       " ',',\n",
       " '\"',\n",
       " 'was',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'axioms',\n",
       " 'he',\n",
       " 'laid',\n",
       " 'down',\n",
       " 'across',\n",
       " 'the',\n",
       " 'Sevres',\n",
       " 'and',\n",
       " 'silver',\n",
       " 'of',\n",
       " 'an',\n",
       " 'exquisitely',\n",
       " 'appointed',\n",
       " 'luncheon-table',\n",
       " ',',\n",
       " 'when',\n",
       " ',',\n",
       " 'on',\n",
       " 'a',\n",
       " 'later',\n",
       " 'day',\n",
       " ',',\n",
       " 'I',\n",
       " 'had',\n",
       " 'again',\n",
       " 'run',\n",
       " 'over',\n",
       " 'from',\n",
       " 'Monte',\n",
       " 'Carlo',\n",
       " ';',\n",
       " 'and',\n",
       " 'Mrs',\n",
       " '.',\n",
       " 'Gisburn',\n",
       " ',',\n",
       " 'beaming',\n",
       " 'on',\n",
       " 'him',\n",
       " ',',\n",
       " 'added',\n",
       " 'for',\n",
       " 'my',\n",
       " 'enlightenment',\n",
       " ':',\n",
       " '\"',\n",
       " 'Jack',\n",
       " 'is',\n",
       " 'so',\n",
       " 'morbidly',\n",
       " 'sensitive',\n",
       " 'to',\n",
       " 'every',\n",
       " 'form',\n",
       " 'of',\n",
       " 'beauty',\n",
       " '.',\n",
       " '\"',\n",
       " 'Poor',\n",
       " 'Jack',\n",
       " '!',\n",
       " 'It',\n",
       " 'had',\n",
       " 'always',\n",
       " 'been',\n",
       " 'his',\n",
       " 'fate',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72352867",
   "metadata": {},
   "source": [
    "The total number of tokens is `4690` without whitespaces.\n",
    "Let's get the first 30 tokens for a quick visual check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae73ea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d98dd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in', 'the', 'height', 'of', 'his', 'glory', ',', 'he', 'had', 'dropped', 'his', 'painting', ',', 'married', 'a', 'rich', 'widow', ',', 'and', 'established', 'himself', 'in', 'a', 'villa', 'on', 'the', 'Riviera', '.', '(', 'Though', 'I']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed[:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e749f",
   "metadata": {},
   "source": [
    "The resulting output shows that our tokenizer appears to be handling the text well since all words and special characters are neatly separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aaa4d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['since', 'Grindle', \"'\", 's', 'doing', 'it', 'for', 'me', '!', 'The', 'Strouds', 'stand', 'alone', ',', 'and', 'happen', 'once', '--', 'but', 'there', \"'\", 's', 'no', 'exterminating', 'our', 'kind', 'of', 'art', '.', '\"']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed[-30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af11eb21",
   "metadata": {},
   "source": [
    "## Converting tokens into token IDs\n",
    "\n",
    "\n",
    "Here, we will convert these tokens from a Python string to an integer representation to produce the so-called token IDs. This conversion is an intermediate step before converting the `token IDs` into `embedding` vectors. \n",
    "\n",
    "To map the previously generated tokens into token IDs, we have to build a so-called vocabulary first. This vocabulary defines how we map each unique word and special character to a unique integer.\n",
    "\n",
    "![Alt text](../../assests/token-IDs.png)\n",
    "\n",
    "We build a vocabulary by tokenizing the entire text in a training dataset into individual tokens. These individual tokens are then sorted alphabetically, and duplicate tokens are removed. The unique tokens are then aggregated into a vocabulary that defines a mapping from each unique token to a unique integer value. The depicted vocabulary is purposefully small for illustration purposes and contains no punctuation or special characters for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1afd920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1130\n"
     ]
    }
   ],
   "source": [
    "# Let's create a list of all unique tokens and sort them alphabetically to determine the vocabulary size\n",
    "\n",
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42090bee",
   "metadata": {},
   "source": [
    "After determining that the vocabulary size is 1,130 via the above code, we create the vocabulary and print its first 51 entries for illustration purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3711238d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('!', 0)\n",
      "('\"', 1)\n",
      "(\"'\", 2)\n",
      "('(', 3)\n",
      "(')', 4)\n",
      "(',', 5)\n",
      "('--', 6)\n",
      "('.', 7)\n",
      "(':', 8)\n",
      "(';', 9)\n",
      "('?', 10)\n",
      "('A', 11)\n",
      "('Ah', 12)\n",
      "('Among', 13)\n",
      "('And', 14)\n",
      "('Are', 15)\n",
      "('Arrt', 16)\n",
      "('As', 17)\n",
      "('At', 18)\n",
      "('Be', 19)\n",
      "('Begin', 20)\n",
      "('Burlington', 21)\n",
      "('But', 22)\n",
      "('By', 23)\n",
      "('Carlo', 24)\n",
      "('Chicago', 25)\n",
      "('Claude', 26)\n",
      "('Come', 27)\n",
      "('Croft', 28)\n",
      "('Destroyed', 29)\n",
      "('Devonshire', 30)\n",
      "('Don', 31)\n",
      "('Dubarry', 32)\n",
      "('Emperors', 33)\n",
      "('Florence', 34)\n",
      "('For', 35)\n",
      "('Gallery', 36)\n",
      "('Gideon', 37)\n",
      "('Gisburn', 38)\n",
      "('Gisburns', 39)\n",
      "('Grafton', 40)\n",
      "('Greek', 41)\n",
      "('Grindle', 42)\n",
      "('Grindles', 43)\n",
      "('HAD', 44)\n",
      "('Had', 45)\n",
      "('Hang', 46)\n",
      "('Has', 47)\n",
      "('He', 48)\n",
      "('Her', 49)\n",
      "('Hermia', 50)\n",
      "('His', 51)\n"
     ]
    }
   ],
   "source": [
    "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5581e1f",
   "metadata": {},
   "source": [
    "As we can see, based on the output above, the dictionary contains individual tokens associated with unique integer labels. Our next goal is to apply this vocabulary to convert new text into token IDs.\n",
    "\n",
    "![Alt text](../../assests/tokenization-sample-text.png)\n",
    "\n",
    "Let's implement a complete tokenizer class in Python with an `encode` method that splits text into tokens and carries out the string-to-integer mapping to produce token IDs via the vocabulary. In addition, we implement a `decode` method that carries out the inverse integer-to-string mapping to convert the token IDs back to text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "318329ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a simple text tokenizer\n",
    "\n",
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        # Store the vocabulary as a class attribute for access in the encode and decode methods\n",
    "        self.str_to_int = vocab\n",
    "        # Create an inverse vocabulary that maps token IDs back to the original text tokens\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    # Process input text into token IDs\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    \n",
    "    # Convert token IDs back into text\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7997032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93, 235, 656, 568, 25, 584, 317, 7]\n"
     ]
    }
   ],
   "source": [
    "text = \"The brown man in Chicago is dead.\"\n",
    "new_vocab = {token:integer for integer,token in enumerate(all_words)}\n",
    "\n",
    "new_preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "new_preprocessed = [item.strip() for item in new_preprocessed if item.strip()]\n",
    "# print([s for s in preprocessed])\n",
    "new_ids = [new_vocab[s] for s in new_preprocessed]\n",
    "print(new_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "782185ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The brown man in Chicago is dead.\n"
     ]
    }
   ],
   "source": [
    "int_to_str = {i:s for s,i in new_vocab.items()}\n",
    "text = \" \".join([int_to_str[i] for i in new_ids])\n",
    "text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d279b9fd",
   "metadata": {},
   "source": [
    "### **Core Components of the `SimpleTokenizerV1` Python class above**\n",
    "\n",
    "\n",
    "- **`str_to_int`**: Dictionary mapping strings (words/punctuation) to integer IDs\n",
    "- **`int_to_str`**: Reverse dictionary mapping integer IDs back to strings\n",
    "\n",
    "##### Encoding Process (`encode` method):\n",
    "1. **Splits text** using regex to separate words from punctuation and whitespace\n",
    "2. **Removes empty strings** and strips whitespace\n",
    "3. **Converts each token** to its corresponding integer ID using the vocabulary\n",
    "\n",
    "##### Decoding Process (`decode` method):\n",
    "1. **Converts IDs back** to strings and joins with spaces\n",
    "2. **Cleans up formatting** by removing unnecessary spaces before punctuation\n",
    "3. **Returns properly formatted** text\n",
    "\n",
    "##### Key Characteristics:\n",
    "- **Rule-based tokenization** (not learned from data)\n",
    "- **Preserves punctuation** as separate tokens\n",
    "- **Simple vocabulary mapping** between text and numbers\n",
    "- **Reversible** - can encode and decode without information loss\n",
    "\n",
    "This is a basic tokenizer similar to early NLP approaches, contrasting with modern subword tokenizers like `BPE` or `WordPiece` used in transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5cc76d",
   "metadata": {},
   "source": [
    "![Alt text](../../assests/inverse-vocab.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7750d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"It's the last he painted, you know, Mrs. Gisburn said with pardonable pride.\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8958dce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56, 2, 850, 988, 602]\n"
     ]
    }
   ],
   "source": [
    "print(ids[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076838ff",
   "metadata": {},
   "source": [
    "We can decode the integers back into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f04a3333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It' s the last he painted, you know, Mrs. Gisburn said with pardonable pride.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab90c3e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It' s the last he painted, you know, Mrs. Gisburn said with pardonable pride.\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf03b78",
   "metadata": {},
   "source": [
    "Based on the output above, we can see that the decode method successfully converted the token IDs back into the original text. \n",
    "\n",
    "So far, so good. We implemented a tokenizer capable of tokenizing and de-tokenizing text based on a snippet from the training set. Let's now apply it to a new text sample that is not contained in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f1e0043",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'extend'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m new_text = \u001b[33m\"\u001b[39m\u001b[33mWe can extend consciousness and life beyond Earth\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_text\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mSimpleTokenizerV1.encode\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     12\u001b[39m preprocessed = re.split(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m([,.:;?_!\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m]|--|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms)\u001b[39m\u001b[33m'\u001b[39m, text)\n\u001b[32m     13\u001b[39m preprocessed = [\n\u001b[32m     14\u001b[39m     item.strip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item.strip()\n\u001b[32m     15\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m ids = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstr_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpreprocessed\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     12\u001b[39m preprocessed = re.split(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m([,.:;?_!\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m]|--|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms)\u001b[39m\u001b[33m'\u001b[39m, text)\n\u001b[32m     13\u001b[39m preprocessed = [\n\u001b[32m     14\u001b[39m     item.strip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item.strip()\n\u001b[32m     15\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m ids = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstr_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[31mKeyError\u001b[39m: 'extend'"
     ]
    }
   ],
   "source": [
    "new_text = \"We can extend consciousness and life beyond Earth\"\n",
    "print(tokenizer.encode(new_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3166f7ec",
   "metadata": {},
   "source": [
    "The problem is that the word \"extend\" was not used in the `The Verdict short` story. Hence, it is not contained in the vocabulary. This highlights the need to consider large and diverse training sets to extend the vocabulary when working on LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723c48f",
   "metadata": {},
   "source": [
    "## Adding special context tokens\n",
    "\n",
    "\n",
    "In the previous section, we implemented a simple tokenizer and applied it to a passage from the training set. In this section, we will modify this tokenizer to handle unknown words.\n",
    "\n",
    "In particular, we will modify the vocabulary and tokenizer we implemented in the previous section, `SimpleTokenizerV2`, to support two new tokens, `<|unk|>` and\n",
    "`<|endoftext|>`.\n",
    "\n",
    "\n",
    "![Alt text](../../assests/special-tokens.png)\n",
    "\n",
    "\n",
    "we can modify the tokenizer to use an `<|unk|>` token if it encounters a word that is not part of the vocabulary. Furthermore, we add a token between unrelated texts. For example, when training `GPT-like` LLMs on multiple independent documents or books, it is common to insert a token before each document or book that\n",
    "follows a previous text source. This helps the LLM understand that, although these text sources are concatenated for training, they are, in fact, unrelated.\n",
    "\n",
    "- Some tokenizers use special tokens to help the LLM with additional context\n",
    "\n",
    "- Some of these special tokens are\n",
    "\n",
    "  - `[BOS]` (beginning of sequence) marks the beginning of text\n",
    "  - `[EOS]` (end of sequence) marks where the text ends (this is usually used to concatenate multiple unrelated texts, e.g., two different Wikipedia articles or two different books, and so on)\n",
    "  - `[PAD]` (padding) if we train LLMs with a batch size greater than 1 (we may include multiple texts with different lengths; with the padding token we pad the shorter texts to the longest length so that all texts have an equal length)\n",
    "\n",
    "- `[UNK]` to represent words that are not included in the vocabulary.\n",
    "- Note that GPT-2 does not need any of these tokens mentioned above but only uses an `<|endoftext|>` token to reduce complexity.\n",
    "- The `<|endoftext|>` is analogous to the `[EOS]` token mentioned above.\n",
    "- GPT also uses the `<|endoftext|>` for padding (since we typically use a mask when training on batched inputs, we would not attend padded tokens anyways, so it does not matter what these tokens are).\n",
    "- `GPT-2` does not use an `<UNK>` token for out-of-vocabulary words; instead, `GPT-2` uses a `byte-pair encoding (BPE)` tokenizer, which breaks down words into subword units which we will discuss in a later section.\n",
    "\n",
    "![Alt text](../../assests/end-of-text.png)\n",
    "\n",
    "- We use the `<|endoftext|>` tokens between two independent sources of text:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eae109",
   "metadata": {},
   "source": [
    "Let's see what happens if we tokenize the following text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b95c056",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Hello'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m tokenizer = SimpleTokenizerV1(vocab)\n\u001b[32m      3\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33mHello, do you like tea. Is this-- a test?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mSimpleTokenizerV1.encode\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m     12\u001b[39m preprocessed = re.split(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m([,.:;?_!\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m]|--|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms)\u001b[39m\u001b[33m'\u001b[39m, text)\n\u001b[32m     13\u001b[39m preprocessed = [\n\u001b[32m     14\u001b[39m     item.strip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item.strip()\n\u001b[32m     15\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m ids = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstr_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpreprocessed\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     12\u001b[39m preprocessed = re.split(\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m\u001b[33m([,.:;?_!\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m()\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33m]|--|\u001b[39m\u001b[33m\\\u001b[39m\u001b[33ms)\u001b[39m\u001b[33m'\u001b[39m, text)\n\u001b[32m     13\u001b[39m preprocessed = [\n\u001b[32m     14\u001b[39m     item.strip() \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m preprocessed \u001b[38;5;28;01mif\u001b[39;00m item.strip()\n\u001b[32m     15\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m ids = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstr_to_int\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m preprocessed]\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ids\n",
      "\u001b[31mKeyError\u001b[39m: 'Hello'"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "\n",
    "text = \"Hello, do you like tea. Is this-- a test?\"\n",
    "\n",
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d7a635",
   "metadata": {},
   "source": [
    "- The above produces an error because the word `\"Hello\"` is not contained in the vocabulary.\n",
    "\n",
    "- To deal with such cases, we can add special tokens like `\"<|unk|>\"` to the vocabulary to represent unknown words.\n",
    "\n",
    "- Since we are already extending the vocabulary, let's add another token called `\"<|endoftext|>\"` which is used in `GPT-2` training to denote the end of a text (and it's also used between concatenated text, like if our training datasets consists of multiple articles, books, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd82ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82752b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'!': 0, '\"': 1, \"'\": 2, '(': 3, ')': 4, ',': 5, '--': 6, '.': 7, ':': 8, ';': 9, '?': 10, 'A': 11, 'Ah': 12, 'Among': 13, 'And': 14, 'Are': 15, 'Arrt': 16, 'As': 17, 'At': 18, 'Be': 19, 'Begin': 20, 'Burlington': 21, 'But': 22, 'By': 23, 'Carlo': 24, 'Chicago': 25, 'Claude': 26, 'Come': 27, 'Croft': 28, 'Destroyed': 29, 'Devonshire': 30, 'Don': 31, 'Dubarry': 32, 'Emperors': 33, 'Florence': 34, 'For': 35, 'Gallery': 36, 'Gideon': 37, 'Gisburn': 38, 'Gisburns': 39, 'Grafton': 40, 'Greek': 41, 'Grindle': 42, 'Grindles': 43, 'HAD': 44, 'Had': 45, 'Hang': 46, 'Has': 47, 'He': 48, 'Her': 49, 'Hermia': 50, 'His': 51, 'How': 52, 'I': 53, 'If': 54, 'In': 55, 'It': 56, 'Jack': 57, 'Jove': 58, 'Just': 59, 'Lord': 60, 'Made': 61, 'Miss': 62, 'Money': 63, 'Monte': 64, 'Moon-dancers': 65, 'Mr': 66, 'Mrs': 67, 'My': 68, 'Never': 69, 'No': 70, 'Now': 71, 'Nutley': 72, 'Of': 73, 'Oh': 74, 'On': 75, 'Once': 76, 'Only': 77, 'Or': 78, 'Perhaps': 79, 'Poor': 80, 'Professional': 81, 'Renaissance': 82, 'Rickham': 83, 'Riviera': 84, 'Rome': 85, 'Russian': 86, 'Sevres': 87, 'She': 88, 'Stroud': 89, 'Strouds': 90, 'Suddenly': 91, 'That': 92, 'The': 93, 'Then': 94, 'There': 95, 'They': 96, 'This': 97, 'Those': 98, 'Though': 99, 'Thwing': 100, 'Thwings': 101, 'To': 102, 'Usually': 103, 'Venetian': 104, 'Victor': 105, 'Was': 106, 'We': 107, 'Well': 108, 'What': 109, 'When': 110, 'Why': 111, 'Yes': 112, 'You': 113, '_': 114, 'a': 115, 'abdication': 116, 'able': 117, 'about': 118, 'above': 119, 'abruptly': 120, 'absolute': 121, 'absorbed': 122, 'absurdity': 123, 'academic': 124, 'accuse': 125, 'accustomed': 126, 'across': 127, 'activity': 128, 'add': 129, 'added': 130, 'admirers': 131, 'adopted': 132, 'adulation': 133, 'advance': 134, 'aesthetic': 135, 'affect': 136, 'afraid': 137, 'after': 138, 'afterward': 139, 'again': 140, 'ago': 141, 'ah': 142, 'air': 143, 'alive': 144, 'all': 145, 'almost': 146, 'alone': 147, 'along': 148, 'always': 149, 'am': 150, 'amazement': 151, 'amid': 152, 'among': 153, 'amplest': 154, 'amusing': 155, 'an': 156, 'and': 157, 'another': 158, 'answer': 159, 'answered': 160, 'any': 161, 'anything': 162, 'anywhere': 163, 'apparent': 164, 'apparently': 165, 'appearance': 166, 'appeared': 167, 'appointed': 168, 'are': 169, 'arm': 170, 'arm-chair': 171, 'arm-chairs': 172, 'arms': 173, 'art': 174, 'articles': 175, 'artist': 176, 'as': 177, 'aside': 178, 'asked': 179, 'at': 180, 'atmosphere': 181, 'atom': 182, 'attack': 183, 'attention': 184, 'attitude': 185, 'audacities': 186, 'away': 187, 'awful': 188, 'axioms': 189, 'azaleas': 190, 'back': 191, 'background': 192, 'balance': 193, 'balancing': 194, 'balustraded': 195, 'basking': 196, 'bath-rooms': 197, 'be': 198, 'beaming': 199, 'bean-stalk': 200, 'bear': 201, 'beard': 202, 'beauty': 203, 'became': 204, 'because': 205, 'becoming': 206, 'bed': 207, 'been': 208, 'before': 209, 'began': 210, 'begun': 211, 'behind': 212, 'being': 213, 'believed': 214, 'beneath': 215, 'bespoke': 216, 'better': 217, 'between': 218, 'big': 219, 'bits': 220, 'bitterness': 221, 'blocked': 222, 'born': 223, 'borne': 224, 'boudoir': 225, 'bravura': 226, 'break': 227, 'breaking': 228, 'breathing': 229, 'bric-a-brac': 230, 'briefly': 231, 'brings': 232, 'bronzes': 233, 'brought': 234, 'brown': 235, 'brush': 236, 'bull': 237, 'business': 238, 'but': 239, 'buying': 240, 'by': 241, 'called': 242, 'came': 243, 'can': 244, 'canvas': 245, 'canvases': 246, 'cards': 247, 'care': 248, 'career': 249, 'caught': 250, 'central': 251, 'chair': 252, 'chap': 253, 'characteristic': 254, 'charming': 255, 'cheap': 256, 'check': 257, 'cheeks': 258, 'chest': 259, 'chimney-piece': 260, 'chucked': 261, 'cigar': 262, 'cigarette': 263, 'cigars': 264, 'circulation': 265, 'circumstance': 266, 'circus-clown': 267, 'claimed': 268, 'clasping': 269, 'clear': 270, 'cleverer': 271, 'close': 272, 'clue': 273, 'coat': 274, 'collapsed': 275, 'colour': 276, 'come': 277, 'comfortable': 278, 'coming': 279, 'companion': 280, 'compared': 281, 'complex': 282, 'confident': 283, 'congesting': 284, 'conjugal': 285, 'constraint': 286, 'consummate': 287, 'contended': 288, 'continued': 289, 'corner': 290, 'corrected': 291, 'could': 292, 'couldn': 293, 'count': 294, 'countenance': 295, 'couple': 296, 'course': 297, 'covered': 298, 'craft': 299, 'cried': 300, 'crossed': 301, 'crowned': 302, 'crumbled': 303, 'cry': 304, 'cured': 305, 'curiosity': 306, 'curious': 307, 'current': 308, 'curtains': 309, 'd': 310, 'dabble': 311, 'damask': 312, 'dark': 313, 'dashed': 314, 'day': 315, 'days': 316, 'dead': 317, 'deadening': 318, 'dear': 319, 'deep': 320, 'deerhound': 321, 'degree': 322, 'delicate': 323, 'demand': 324, 'denied': 325, 'deploring': 326, 'deprecating': 327, 'deprecatingly': 328, 'desire': 329, 'destroyed': 330, 'destruction': 331, 'desultory': 332, 'detail': 333, 'diagnosis': 334, 'did': 335, 'didn': 336, 'died': 337, 'dim': 338, 'dimmest': 339, 'dingy': 340, 'dining-room': 341, 'disarming': 342, 'discovery': 343, 'discrimination': 344, 'discussion': 345, 'disdain': 346, 'disdained': 347, 'disease': 348, 'disguised': 349, 'display': 350, 'dissatisfied': 351, 'distinguished': 352, 'distract': 353, 'divert': 354, 'do': 355, 'doesn': 356, 'doing': 357, 'domestic': 358, 'don': 359, 'done': 360, 'donkey': 361, 'down': 362, 'dozen': 363, 'dragged': 364, 'drawing-room': 365, 'drawing-rooms': 366, 'drawn': 367, 'dress-closets': 368, 'drew': 369, 'dropped': 370, 'each': 371, 'earth': 372, 'ease': 373, 'easel': 374, 'easy': 375, 'echoed': 376, 'economy': 377, 'effect': 378, 'effects': 379, 'efforts': 380, 'egregious': 381, 'eighteenth-century': 382, 'elbow': 383, 'elegant': 384, 'else': 385, 'embarrassed': 386, 'enabled': 387, 'end': 388, 'endless': 389, 'enjoy': 390, 'enlightenment': 391, 'enough': 392, 'ensuing': 393, 'equally': 394, 'equanimity': 395, 'escape': 396, 'established': 397, 'etching': 398, 'even': 399, 'event': 400, 'ever': 401, 'everlasting': 402, 'every': 403, 'exasperated': 404, 'except': 405, 'excuse': 406, 'excusing': 407, 'existed': 408, 'expected': 409, 'exquisite': 410, 'exquisitely': 411, 'extenuation': 412, 'exterminating': 413, 'extracting': 414, 'eye': 415, 'eyebrows': 416, 'eyes': 417, 'face': 418, 'faces': 419, 'fact': 420, 'faded': 421, 'failed': 422, 'failure': 423, 'fair': 424, 'faith': 425, 'false': 426, 'familiar': 427, 'famille-verte': 428, 'fancy': 429, 'fashionable': 430, 'fate': 431, 'feather': 432, 'feet': 433, 'fell': 434, 'fellow': 435, 'felt': 436, 'few': 437, 'fewer': 438, 'finality': 439, 'find': 440, 'fingers': 441, 'first': 442, 'fit': 443, 'fitting': 444, 'five': 445, 'flash': 446, 'flashed': 447, 'florid': 448, 'flowers': 449, 'fluently': 450, 'flung': 451, 'follow': 452, 'followed': 453, 'fond': 454, 'footstep': 455, 'for': 456, 'forced': 457, 'forcing': 458, 'forehead': 459, 'foreign': 460, 'foreseen': 461, 'forgive': 462, 'forgotten': 463, 'form': 464, 'formed': 465, 'forming': 466, 'forward': 467, 'fostered': 468, 'found': 469, 'foundations': 470, 'fragment': 471, 'fragments': 472, 'frame': 473, 'frames': 474, 'frequently': 475, 'friend': 476, 'from': 477, 'full': 478, 'fullest': 479, 'furiously': 480, 'furrowed': 481, 'garlanded': 482, 'garlands': 483, 'gave': 484, 'genial': 485, 'genius': 486, 'gesture': 487, 'get': 488, 'getting': 489, 'give': 490, 'given': 491, 'glad': 492, 'glanced': 493, 'glimpse': 494, 'gloried': 495, 'glory': 496, 'go': 497, 'going': 498, 'gone': 499, 'good': 500, 'good-breeding': 501, 'good-humoured': 502, 'got': 503, 'grace': 504, 'gradually': 505, 'gray': 506, 'grayish': 507, 'great': 508, 'greatest': 509, 'greatness': 510, 'grew': 511, 'groping': 512, 'growing': 513, 'had': 514, 'hadn': 515, 'hair': 516, 'half': 517, 'half-light': 518, 'half-mechanically': 519, 'hall': 520, 'hand': 521, 'hands': 522, 'handsome': 523, 'hanging': 524, 'happen': 525, 'happened': 526, 'hard': 527, 'hardly': 528, 'has': 529, 'have': 530, 'haven': 531, 'having': 532, 'he': 533, 'head': 534, 'hear': 535, 'heard': 536, 'heart': 537, 'height': 538, 'her': 539, 'here': 540, 'hermit': 541, 'herself': 542, 'hesitations': 543, 'hide': 544, 'high': 545, 'him': 546, 'himself': 547, 'hint': 548, 'his': 549, 'history': 550, 'holding': 551, 'home': 552, 'honour': 553, 'hooded': 554, 'hostess': 555, 'hot-house': 556, 'hour': 557, 'hours': 558, 'house': 559, 'how': 560, 'hung': 561, 'husband': 562, 'idea': 563, 'idle': 564, 'idling': 565, 'if': 566, 'immediately': 567, 'in': 568, 'incense': 569, 'indifferent': 570, 'inevitable': 571, 'inevitably': 572, 'inflexible': 573, 'insensible': 574, 'insignificant': 575, 'instinctively': 576, 'instructive': 577, 'interesting': 578, 'into': 579, 'ironic': 580, 'irony': 581, 'irrelevance': 582, 'irrevocable': 583, 'is': 584, 'it': 585, 'its': 586, 'itself': 587, 'jardiniere': 588, 'jealousy': 589, 'just': 590, 'keep': 591, 'kept': 592, 'kind': 593, 'knees': 594, 'knew': 595, 'know': 596, 'known': 597, 'laid': 598, 'lair': 599, 'landing': 600, 'language': 601, 'last': 602, 'late': 603, 'later': 604, 'latter': 605, 'laugh': 606, 'laughed': 607, 'lay': 608, 'leading': 609, 'lean': 610, 'learned': 611, 'least': 612, 'leathery': 613, 'leave': 614, 'led': 615, 'left': 616, 'leisure': 617, 'lends': 618, 'lent': 619, 'let': 620, 'lies': 621, 'life': 622, 'life-likeness': 623, 'lift': 624, 'lifted': 625, 'light': 626, 'lightly': 627, 'like': 628, 'liked': 629, 'line': 630, 'lines': 631, 'lingered': 632, 'lips': 633, 'lit': 634, 'little': 635, 'live': 636, 'll': 637, 'loathing': 638, 'long': 639, 'longed': 640, 'longer': 641, 'look': 642, 'looked': 643, 'looking': 644, 'lose': 645, 'loss': 646, 'lounging': 647, 'lovely': 648, 'lucky': 649, 'lump': 650, 'luncheon-table': 651, 'luxury': 652, 'lying': 653, 'made': 654, 'make': 655, 'man': 656, 'manage': 657, 'managed': 658, 'mantel-piece': 659, 'marble': 660, 'married': 661, 'may': 662, 'me': 663, 'meant': 664, 'mediocrity': 665, 'medium': 666, 'mentioned': 667, 'mere': 668, 'merely': 669, 'met': 670, 'might': 671, 'mighty': 672, 'millionaire': 673, 'mine': 674, 'minute': 675, 'minutes': 676, 'mirrors': 677, 'modest': 678, 'modesty': 679, 'moment': 680, 'money': 681, 'monumental': 682, 'mood': 683, 'morbidly': 684, 'more': 685, 'most': 686, 'mourn': 687, 'mourned': 688, 'moustache': 689, 'moved': 690, 'much': 691, 'muddling': 692, 'multiplied': 693, 'murmur': 694, 'muscles': 695, 'must': 696, 'my': 697, 'myself': 698, 'mysterious': 699, 'naive': 700, 'near': 701, 'nearly': 702, 'negatived': 703, 'nervous': 704, 'nervousness': 705, 'neutral': 706, 'never': 707, 'next': 708, 'no': 709, 'none': 710, 'not': 711, 'note': 712, 'nothing': 713, 'now': 714, 'nymphs': 715, 'oak': 716, 'obituary': 717, 'object': 718, 'objects': 719, 'occurred': 720, 'oddly': 721, 'of': 722, 'off': 723, 'often': 724, 'oh': 725, 'old': 726, 'on': 727, 'once': 728, 'one': 729, 'ones': 730, 'only': 731, 'onto': 732, 'open': 733, 'or': 734, 'other': 735, 'our': 736, 'ourselves': 737, 'out': 738, 'outline': 739, 'oval': 740, 'over': 741, 'own': 742, 'packed': 743, 'paid': 744, 'paint': 745, 'painted': 746, 'painter': 747, 'painting': 748, 'pale': 749, 'paled': 750, 'palm-trees': 751, 'panel': 752, 'panelling': 753, 'pardonable': 754, 'pardoned': 755, 'part': 756, 'passages': 757, 'passing': 758, 'past': 759, 'pastels': 760, 'pathos': 761, 'patient': 762, 'people': 763, 'perceptible': 764, 'perfect': 765, 'persistence': 766, 'persuasively': 767, 'phrase': 768, 'picture': 769, 'pictures': 770, 'pines': 771, 'pink': 772, 'place': 773, 'placed': 774, 'plain': 775, 'platitudes': 776, 'pleased': 777, 'pockets': 778, 'point': 779, 'poised': 780, 'poor': 781, 'portrait': 782, 'posing': 783, 'possessed': 784, 'poverty': 785, 'predicted': 786, 'preliminary': 787, 'presenting': 788, 'prestidigitation': 789, 'pretty': 790, 'previous': 791, 'price': 792, 'pride': 793, 'princely': 794, 'prism': 795, 'problem': 796, 'proclaiming': 797, 'prodigious': 798, 'profusion': 799, 'protest': 800, 'prove': 801, 'public': 802, 'purblind': 803, 'purely': 804, 'pushed': 805, 'put': 806, 'qualities': 807, 'quality': 808, 'queerly': 809, 'question': 810, 'quickly': 811, 'quietly': 812, 'quite': 813, 'quote': 814, 'rain': 815, 'raised': 816, 'random': 817, 'rather': 818, 're': 819, 'real': 820, 'really': 821, 'reared': 822, 'reason': 823, 'reassurance': 824, 'recovering': 825, 'recreated': 826, 'reflected': 827, 'reflection': 828, 'regrets': 829, 'relatively': 830, 'remained': 831, 'remember': 832, 'reminded': 833, 'repeating': 834, 'represented': 835, 'reproduction': 836, 'resented': 837, 'resolve': 838, 'resources': 839, 'rest': 840, 'rich': 841, 'ridiculous': 842, 'robbed': 843, 'romantic': 844, 'room': 845, 'rose': 846, 'rs': 847, 'rule': 848, 'run': 849, 's': 850, 'said': 851, 'same': 852, 'satisfaction': 853, 'savour': 854, 'saw': 855, 'say': 856, 'saying': 857, 'says': 858, 'scorn': 859, 'scornful': 860, 'secret': 861, 'see': 862, 'seemed': 863, 'seen': 864, 'self-confident': 865, 'send': 866, 'sensation': 867, 'sensitive': 868, 'sent': 869, 'serious': 870, 'set': 871, 'sex': 872, 'shade': 873, 'shaking': 874, 'shall': 875, 'she': 876, 'shirked': 877, 'short': 878, 'should': 879, 'shoulder': 880, 'shoulders': 881, 'show': 882, 'showed': 883, 'showy': 884, 'shrug': 885, 'shrugged': 886, 'sight': 887, 'sign': 888, 'silent': 889, 'silver': 890, 'similar': 891, 'simpleton': 892, 'simplifications': 893, 'simply': 894, 'since': 895, 'single': 896, 'sitter': 897, 'sitters': 898, 'sketch': 899, 'skill': 900, 'slight': 901, 'slightly': 902, 'slowly': 903, 'small': 904, 'smile': 905, 'smiling': 906, 'sneer': 907, 'so': 908, 'solace': 909, 'some': 910, 'somebody': 911, 'something': 912, 'spacious': 913, 'spaniel': 914, 'speaking-tubes': 915, 'speculations': 916, 'spite': 917, 'splash': 918, 'square': 919, 'stairs': 920, 'stammer': 921, 'stand': 922, 'standing': 923, 'started': 924, 'stay': 925, 'still': 926, 'stocked': 927, 'stood': 928, 'stopped': 929, 'stopping': 930, 'straddling': 931, 'straight': 932, 'strain': 933, 'straining': 934, 'strange': 935, 'straw': 936, 'stream': 937, 'stroke': 938, 'strokes': 939, 'strolled': 940, 'strongest': 941, 'strongly': 942, 'struck': 943, 'studio': 944, 'stuff': 945, 'subject': 946, 'substantial': 947, 'suburban': 948, 'such': 949, 'suddenly': 950, 'suffered': 951, 'sugar': 952, 'suggested': 953, 'sunburn': 954, 'sunburnt': 955, 'sunlit': 956, 'superb': 957, 'sure': 958, 'surest': 959, 'surface': 960, 'surprise': 961, 'surprised': 962, 'surrounded': 963, 'suspected': 964, 'sweetly': 965, 'sweetness': 966, 'swelling': 967, 'swept': 968, 'swum': 969, 't': 970, 'table': 971, 'take': 972, 'taken': 973, 'talking': 974, 'tea': 975, 'tears': 976, 'technicalities': 977, 'technique': 978, 'tell': 979, 'tells': 980, 'tempting': 981, 'terra-cotta': 982, 'terrace': 983, 'terraces': 984, 'terribly': 985, 'than': 986, 'that': 987, 'the': 988, 'their': 989, 'them': 990, 'then': 991, 'there': 992, 'therefore': 993, 'they': 994, 'thin': 995, 'thing': 996, 'things': 997, 'think': 998, 'this': 999, 'thither': 1000, 'those': 1001, 'though': 1002, 'thought': 1003, 'three': 1004, 'threshold': 1005, 'threw': 1006, 'through': 1007, 'throwing': 1008, 'tie': 1009, 'till': 1010, 'time': 1011, 'timorously': 1012, 'tinge': 1013, 'tips': 1014, 'tired': 1015, 'to': 1016, 'told': 1017, 'tone': 1018, 'tones': 1019, 'too': 1020, 'took': 1021, 'tottering': 1022, 'touched': 1023, 'toward': 1024, 'trace': 1025, 'trade': 1026, 'transmute': 1027, 'traps': 1028, 'travelled': 1029, 'tribute': 1030, 'tributes': 1031, 'tricks': 1032, 'tried': 1033, 'trouser-presses': 1034, 'true': 1035, 'truth': 1036, 'turned': 1037, 'twenty': 1038, 'twenty-four': 1039, 'twice': 1040, 'twirling': 1041, 'unaccountable': 1042, 'uncertain': 1043, 'under': 1044, 'underlay': 1045, 'underneath': 1046, 'understand': 1047, 'unexpected': 1048, 'untouched': 1049, 'unusual': 1050, 'up': 1051, 'up-stream': 1052, 'upon': 1053, 'upset': 1054, 'upstairs': 1055, 'us': 1056, 'used': 1057, 'usual': 1058, 'value': 1059, 'varnishing': 1060, 'vases': 1061, 've': 1062, 'veins': 1063, 'velveteen': 1064, 'very': 1065, 'villa': 1066, 'vindicated': 1067, 'virtuosity': 1068, 'vista': 1069, 'vocation': 1070, 'voice': 1071, 'wall': 1072, 'wander': 1073, 'want': 1074, 'wanted': 1075, 'wants': 1076, 'was': 1077, 'wasn': 1078, 'watched': 1079, 'watching': 1080, 'water-colour': 1081, 'waves': 1082, 'way': 1083, 'weekly': 1084, 'weeks': 1085, 'welcome': 1086, 'went': 1087, 'were': 1088, 'what': 1089, 'when': 1090, 'whenever': 1091, 'where': 1092, 'which': 1093, 'while': 1094, 'white': 1095, 'white-panelled': 1096, 'who': 1097, 'whole': 1098, 'whom': 1099, 'why': 1100, 'wide': 1101, 'widow': 1102, 'wife': 1103, 'wild': 1104, 'wincing': 1105, 'window-curtains': 1106, 'wish': 1107, 'with': 1108, 'without': 1109, 'wits': 1110, 'woman': 1111, 'women': 1112, 'won': 1113, 'wonder': 1114, 'wondered': 1115, 'word': 1116, 'work': 1117, 'working': 1118, 'worth': 1119, 'would': 1120, 'wouldn': 1121, 'year': 1122, 'years': 1123, 'yellow': 1124, 'yet': 1125, 'you': 1126, 'younger': 1127, 'your': 1128, 'yourself': 1129, '<|endoftext|>': 1130, '<|unk|>': 1131}\n"
     ]
    }
   ],
   "source": [
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f58b64c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1130, 1131, 6)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[\"<|endoftext|>\"], vocab[\"<|unk|>\"], vocab[\"--\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96f8fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6890b86",
   "metadata": {},
   "source": [
    "Based on the output of the print statement above, the new vocabulary size is 1132 (the vocabulary size in the previous section was 1130).\n",
    "\n",
    "As an additional quick check, let's print the last 5 entries of the updated vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9cca48fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f81cd5",
   "metadata": {},
   "source": [
    "We also need to adjust the `tokenizer` accordingly so that it knows when and how to use the new `<unk>` token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c1f5e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple text tokenizer that handles unknown words\n",
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "    \n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        # replace unknown words by <|unk|> tokens\n",
    "        preprocessed = [\n",
    "            item if item in self.str_to_int\n",
    "            else \"<|unk|>\" for item in preprocessed\n",
    "        ]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        # Replace spaces before the specified punctuations\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cd6404",
   "metadata": {},
   "source": [
    "Compared to the `SimpleTokenizerV1` the new `SimpleTokenizerV2` replaces unknown words by `<|unk|>` tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffca5305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "\n",
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf9446f",
   "metadata": {},
   "source": [
    "Next, let's tokenize the sample text using the `SimpleTokenizerV2` on the vocab we previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c6fb1dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46b0da3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "42d16fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1131, 5, 355, 1126, 628, 975, 7, 1131, 999, 6, 115, 1131, 10]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5 = \"Hello, do you like tea. Is this-- a test?\"\n",
    "\n",
    "tokenizer.encode(text5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c21aae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|unk|>, do you like tea. <|unk|> this -- a <|unk|>?'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(text5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96d6e2b",
   "metadata": {},
   "source": [
    "Based on comparing the `de-tokenized` text above with the original input text, we know that the training dataset, Edith Wharton's short story The Verdict, did not contain the words `\"Hello\"` and `\"palace.\"`\n",
    "\n",
    "So far, we have discussed tokenization as an essential step in processing text as input to LLMs. Depending on the LLM, some researchers also consider additional special tokens such as the following:\n",
    "\n",
    "- `[BOS] (beginning of sequence)`: This token marks the start of a text. It signifies to the LLM where a piece of content begins.\n",
    "  \n",
    "- `[EOS] (end of sequence)`: This token is positioned at the end of a text, and is especially useful when concatenating multiple unrelated texts, similar to `<|endoftext|>`. For instance, when combining two different Wikipedia articles or books, the `[EOS]` token indicates where one article ends and the next one begins.\n",
    "  \n",
    "- `[PAD] (padding)`: When training LLMs with batch sizes larger than one, the batch might contain texts of varying lengths. To ensure all texts have the same length, the shorter texts are extended or \"padded\" using the `[PAD]` token, up to the length of the longest text in the batch.\n",
    "\n",
    "\n",
    "Note that the tokenizer used for GPT models does not need any of these tokens mentioned above but only uses an `<|endoftext|>` token for simplicity. The `<|endoftext|>` is analogous to the `[EOS]` token mentioned above. Also, `<|endoftext|>` is used for padding as well.\n",
    "\n",
    "Moreover, the tokenizer used for GPT models also doesn't use an `<|unk|>` token for out-of-vocabulary words. Instead, GPT models use a `byte pair encoding` tokenizer, which breaks down words into subword units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3aea7e",
   "metadata": {},
   "source": [
    "## Byte pair encoding\n",
    "\n",
    "\n",
    "This section covers a more sophisticated tokenization scheme based on a concept called `byte pair encoding (BPE)`. The BPE tokenizer covered in this section was used to train LLMs such as `GPT-2`, `GPT-3`, and the original model used in `ChatGPT`.\n",
    "\n",
    "Since implementing `BPE` can be relatively complicated, we will use an existing Python open-source library called `tiktoken` (https://github.com/openai/tiktoken), which implements the BPE algorithm very efficiently based on source code in Rust. Similar to other Python libraries, we can install the tiktoken library via Python's pip installer from the terminal:\n",
    "\n",
    "```bash\n",
    "pip install tiktoken\n",
    "```\n",
    "\n",
    "\n",
    "- `GPT-2` used `BytePair encoding (BPE)` as its tokenizer.\n",
    "- It allows the model to break down words that aren't in its predefined vocabulary into smaller subword units or even individual characters, enabling it to handle out-of-vocabulary words.\n",
    "- For instance, if `GPT-2's` vocabulary doesn't have the word `\"unfamiliarword,\"` it might tokenize it as `[\"unfam\", \"iliar\", \"word\"]` or some other subword breakdown, depending on its trained BPE merges.\n",
    "- The original BPE tokenizer can be found here: https://github.com/openai/gpt-2/blob/master/src/encoder.py\n",
    "- In this section, we are using the BPE `tokenizer` from OpenAI's open-source tiktoken library, which implements its core algorithms in Rust to improve computational performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a9cdbfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.11.0\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tiktoken\n",
    "\n",
    "print(\"tiktoken version:\", importlib.metadata.version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a8379082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can instantiate the BPE tokenizer from tiktoken as follows:\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d17c09",
   "metadata": {},
   "source": [
    "The usage of this tokenizer is similar to `SimpleTokenizerV2` we implemented previously via an encode method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "13ee6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n"
     ]
    }
   ],
   "source": [
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "     \"of someunknownPlace.\"\n",
    ")\n",
    "\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a481c9",
   "metadata": {},
   "source": [
    "We can then convert the token IDs back into text using the `decode` method, similar to our `SimpleTokenizerV2` earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c68d713d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26acff",
   "metadata": {},
   "source": [
    "We can make two noteworthy observations based on the token IDs and decoded text above. First, the `<|endoftext|>` token is assigned a relatively large token ID, namely, `50256`. In fact, the BPE tokenizer, which was used to train models such as `GPT-2`, `GPT-3`, and the original model used in ChatGPT, has a total vocabulary size of `50,257`, with\n",
    "`<|endoftext|>` being assigned the largest token ID.\n",
    "\n",
    "\n",
    "Second, the `BPE` tokenizer above encodes and decodes unknown words, such as `\"someunknownPlace\"` correctly. The `BPE` tokenizer can handle any unknown word. How does it achieve this without using `<|unk|>` tokens?\n",
    "\n",
    "\n",
    "The algorithm underlying `BPE` breaks down words that aren't in its predefined vocabulary into smaller subword units or even individual characters, enabling it to handle `out-of-vocabulary` words. So, thanks to the `BPE algorithm`, if the tokenizer encounters an unfamiliar word during tokenization, it can represent it as a sequence of subword tokens or\n",
    "characters, as illustrated below;\n",
    "\n",
    "\n",
    "![Alt text](../../assests/subword-tokens.png)\n",
    "\n",
    "\n",
    "The ability to break down unknown words into individual characters ensures that the tokenizer, and consequently the LLM that is trained with it, can process any text, even if it contains words that were not present in its training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "328d38f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959, 49276, 1547]\n"
     ]
    }
   ],
   "source": [
    "unknown = (\"Akwirw ier sillians\")\n",
    "\n",
    "int_pairs = tokenizer.encode(unknown)\n",
    "print(int_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b36e5dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Akwirw ier sillians'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_pairs = tokenizer.decode(int_pairs)\n",
    "string_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2f7fe",
   "metadata": {},
   "source": [
    "## Data sampling with a sliding window\n",
    "\n",
    "The previous section covered the tokenization steps and conversion from string tokens into integer token IDs in great detail. The next step before we can finally create the embeddings for the LLM is to generate the input-target pairs required for training an LLM.\n",
    "\n",
    "We train LLMs to generate one word at a time, so we want to prepare the training data accordingly where the next word in a sequence represents the target to predict:\n",
    "\n",
    "![Alt text](../../assests/sliding-window.png)\n",
    "\n",
    "Given a text sample, extract input blocks as subsamples that serve as input to the LLM, and the LLM's prediction task during training is to predict the next word that follows the input block. During training, we mask out all words that are past the target. Note that the text shown in this figure would undergo tokenization before the LLM can process it; however, this figure omits the tokenization step for clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a81c2f",
   "metadata": {},
   "source": [
    "Here, we implement a data loader that fetches the input-target pairs depicted in the figure above from the training dataset using a sliding window approach. We will first tokenize the whole `The Verdict short story` we worked with earlier using the `BPE tokenizer` introduced in the previous section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bb8f76fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6ec4f",
   "metadata": {},
   "source": [
    "The above code returns `5145`, the total number of tokens in the training set, after applying the `BPE` tokenizer. \n",
    "\n",
    "- For each text chunk, we want the inputs and targets.\n",
    "- Since we want the model to predict the next word, the targets are the inputs shifted by one position to the right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ee1c5216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[290,\n",
       " 4920,\n",
       " 2241,\n",
       " 287,\n",
       " 257,\n",
       " 4489,\n",
       " 64,\n",
       " 319,\n",
       " 262,\n",
       " 34686,\n",
       " 41976,\n",
       " 13,\n",
       " 357,\n",
       " 10915,\n",
       " 314,\n",
       " 2138,\n",
       " 1807,\n",
       " 340,\n",
       " 561,\n",
       " 423,\n",
       " 587,\n",
       " 10598,\n",
       " 393,\n",
       " 28537,\n",
       " 2014,\n",
       " 198,\n",
       " 198,\n",
       " 1,\n",
       " 464,\n",
       " 6001,\n",
       " 286,\n",
       " 465,\n",
       " 13476,\n",
       " 1,\n",
       " 438,\n",
       " 5562,\n",
       " 373,\n",
       " 644,\n",
       " 262,\n",
       " 1466,\n",
       " 1444,\n",
       " 340,\n",
       " 13,\n",
       " 314,\n",
       " 460,\n",
       " 3285,\n",
       " 9074,\n",
       " 13,\n",
       " 46606,\n",
       " 536,\n",
       " 5469,\n",
       " 438,\n",
       " 14363,\n",
       " 938,\n",
       " 4842,\n",
       " 1650,\n",
       " 353,\n",
       " 438,\n",
       " 2934,\n",
       " 489,\n",
       " 3255,\n",
       " 465,\n",
       " 48422,\n",
       " 540,\n",
       " 450,\n",
       " 67,\n",
       " 3299,\n",
       " 13,\n",
       " 366,\n",
       " 5189,\n",
       " 1781,\n",
       " 340,\n",
       " 338,\n",
       " 1016,\n",
       " 284,\n",
       " 3758,\n",
       " 262,\n",
       " 1988,\n",
       " 286,\n",
       " 616,\n",
       " 4286,\n",
       " 705,\n",
       " 1014,\n",
       " 510,\n",
       " 26,\n",
       " 475,\n",
       " 314,\n",
       " 836,\n",
       " 470,\n",
       " 892,\n",
       " 286,\n",
       " 326,\n",
       " 11,\n",
       " 1770,\n",
       " 13,\n",
       " 8759,\n",
       " 2763,\n",
       " 438,\n",
       " 1169,\n",
       " 2994,\n",
       " 284,\n",
       " 943,\n",
       " 17034,\n",
       " 318,\n",
       " 477,\n",
       " 314,\n",
       " 892,\n",
       " 286,\n",
       " 526,\n",
       " 383,\n",
       " 1573,\n",
       " 11,\n",
       " 319,\n",
       " 9074,\n",
       " 13,\n",
       " 536,\n",
       " 5469,\n",
       " 338,\n",
       " 11914,\n",
       " 11,\n",
       " 33096,\n",
       " 663,\n",
       " 4808,\n",
       " 3808,\n",
       " 62,\n",
       " 355,\n",
       " 996,\n",
       " 484,\n",
       " 547,\n",
       " 12548,\n",
       " 287,\n",
       " 281,\n",
       " 13079,\n",
       " 410,\n",
       " 12523,\n",
       " 286,\n",
       " 22353,\n",
       " 13,\n",
       " 843,\n",
       " 340,\n",
       " 373,\n",
       " 407,\n",
       " 691,\n",
       " 262,\n",
       " 9074,\n",
       " 13,\n",
       " 536,\n",
       " 48819,\n",
       " 508,\n",
       " 25722,\n",
       " 276,\n",
       " 13,\n",
       " 11161,\n",
       " 407,\n",
       " 262,\n",
       " 40123,\n",
       " 18113,\n",
       " 544,\n",
       " 9325,\n",
       " 701,\n",
       " 11,\n",
       " 379,\n",
       " 262,\n",
       " 938,\n",
       " 402,\n",
       " 1617,\n",
       " 261,\n",
       " 12917,\n",
       " 905,\n",
       " 11,\n",
       " 5025,\n",
       " 502,\n",
       " 878,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 338,\n",
       " 366,\n",
       " 31640,\n",
       " 12,\n",
       " 67,\n",
       " 20811,\n",
       " 1,\n",
       " 284,\n",
       " 910,\n",
       " 11,\n",
       " 351,\n",
       " 10953,\n",
       " 287,\n",
       " 607,\n",
       " 2951,\n",
       " 25,\n",
       " 366,\n",
       " 1135,\n",
       " 2236,\n",
       " 407,\n",
       " 804,\n",
       " 2402,\n",
       " 663,\n",
       " 588,\n",
       " 757,\n",
       " 13984,\n",
       " 198,\n",
       " 198,\n",
       " 5779,\n",
       " 28112,\n",
       " 10197,\n",
       " 832,\n",
       " 262,\n",
       " 46475,\n",
       " 286,\n",
       " 18113,\n",
       " 544,\n",
       " 338,\n",
       " 10953,\n",
       " 314,\n",
       " 2936,\n",
       " 1498,\n",
       " 284,\n",
       " 1986,\n",
       " 262,\n",
       " 1109,\n",
       " 351,\n",
       " 1602,\n",
       " 11227,\n",
       " 414,\n",
       " 13,\n",
       " 23676,\n",
       " 3619,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 0,\n",
       " 383,\n",
       " 1466,\n",
       " 550,\n",
       " 925,\n",
       " 683,\n",
       " 438,\n",
       " 270,\n",
       " 373,\n",
       " 15830,\n",
       " 326,\n",
       " 484,\n",
       " 815,\n",
       " 25722,\n",
       " 683,\n",
       " 13,\n",
       " 9754,\n",
       " 465,\n",
       " 898,\n",
       " 1714,\n",
       " 7380,\n",
       " 30090,\n",
       " 547,\n",
       " 2982,\n",
       " 11,\n",
       " 290,\n",
       " 287,\n",
       " 465,\n",
       " 898,\n",
       " 3292,\n",
       " 8941,\n",
       " 257,\n",
       " 4636,\n",
       " 28582,\n",
       " 13,\n",
       " 18612,\n",
       " 35394,\n",
       " 30,\n",
       " 8673,\n",
       " 13,\n",
       " 1002,\n",
       " 340,\n",
       " 547,\n",
       " 11,\n",
       " 262,\n",
       " 15393,\n",
       " 286,\n",
       " 262,\n",
       " 5977,\n",
       " 373,\n",
       " 29178,\n",
       " 3474,\n",
       " 416,\n",
       " 1310,\n",
       " 40559,\n",
       " 11959,\n",
       " 1636,\n",
       " 11,\n",
       " 508,\n",
       " 11,\n",
       " 287,\n",
       " 477,\n",
       " 922,\n",
       " 4562,\n",
       " 11,\n",
       " 3181,\n",
       " 503,\n",
       " 287,\n",
       " 262,\n",
       " 37090,\n",
       " 257,\n",
       " 845,\n",
       " 22665,\n",
       " 366,\n",
       " 672,\n",
       " 270,\n",
       " 2838,\n",
       " 1,\n",
       " 319,\n",
       " 3619,\n",
       " 438,\n",
       " 505,\n",
       " 286,\n",
       " 883,\n",
       " 905,\n",
       " 88,\n",
       " 6685,\n",
       " 42070,\n",
       " 351,\n",
       " 4738,\n",
       " 6276,\n",
       " 871,\n",
       " 326,\n",
       " 314,\n",
       " 423,\n",
       " 2982,\n",
       " 357,\n",
       " 40,\n",
       " 1839,\n",
       " 470,\n",
       " 910,\n",
       " 416,\n",
       " 4150,\n",
       " 8,\n",
       " 3688,\n",
       " 284,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 338,\n",
       " 12036,\n",
       " 13,\n",
       " 843,\n",
       " 523,\n",
       " 438,\n",
       " 14363,\n",
       " 10568,\n",
       " 852,\n",
       " 5729,\n",
       " 11331,\n",
       " 18893,\n",
       " 540,\n",
       " 438,\n",
       " 1169,\n",
       " 5114,\n",
       " 11835,\n",
       " 3724,\n",
       " 503,\n",
       " 11,\n",
       " 290,\n",
       " 11,\n",
       " 355,\n",
       " 9074,\n",
       " 13,\n",
       " 536,\n",
       " 5469,\n",
       " 550,\n",
       " 11001,\n",
       " 11,\n",
       " 262,\n",
       " 2756,\n",
       " 286,\n",
       " 366,\n",
       " 38,\n",
       " 271,\n",
       " 10899,\n",
       " 82,\n",
       " 1,\n",
       " 1816,\n",
       " 510,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 1026,\n",
       " 373,\n",
       " 407,\n",
       " 10597,\n",
       " 1115,\n",
       " 812,\n",
       " 1568,\n",
       " 326,\n",
       " 11,\n",
       " 287,\n",
       " 262,\n",
       " 1781,\n",
       " 286,\n",
       " 257,\n",
       " 1178,\n",
       " 2745,\n",
       " 6,\n",
       " 4686,\n",
       " 1359,\n",
       " 319,\n",
       " 262,\n",
       " 34686,\n",
       " 41976,\n",
       " 11,\n",
       " 340,\n",
       " 6451,\n",
       " 5091,\n",
       " 284,\n",
       " 502,\n",
       " 284,\n",
       " 4240,\n",
       " 1521,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 550,\n",
       " 1813,\n",
       " 510,\n",
       " 465,\n",
       " 12036,\n",
       " 13,\n",
       " 1550,\n",
       " 14580,\n",
       " 11,\n",
       " 340,\n",
       " 1107,\n",
       " 373,\n",
       " 257,\n",
       " 29850,\n",
       " 1917,\n",
       " 13,\n",
       " 1675,\n",
       " 24456,\n",
       " 465,\n",
       " 3656,\n",
       " 561,\n",
       " 423,\n",
       " 587,\n",
       " 1165,\n",
       " 2562,\n",
       " 438,\n",
       " 14363,\n",
       " 3148,\n",
       " 1650,\n",
       " 1010,\n",
       " 550,\n",
       " 587,\n",
       " 6699,\n",
       " 262,\n",
       " 1540,\n",
       " 558,\n",
       " 286,\n",
       " 2282,\n",
       " 326,\n",
       " 9074,\n",
       " 13,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 550,\n",
       " 366,\n",
       " 7109,\n",
       " 14655,\n",
       " 683,\n",
       " 866,\n",
       " 526,\n",
       " 1114,\n",
       " 9074,\n",
       " 13,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 438,\n",
       " 292,\n",
       " 884,\n",
       " 438,\n",
       " 18108,\n",
       " 407,\n",
       " 11196,\n",
       " 10597,\n",
       " 3016,\n",
       " 257,\n",
       " 614,\n",
       " 706,\n",
       " 3619,\n",
       " 338,\n",
       " 10568,\n",
       " 550,\n",
       " 587,\n",
       " 2077,\n",
       " 13,\n",
       " 632,\n",
       " 1244,\n",
       " 307,\n",
       " 326,\n",
       " 339,\n",
       " 550,\n",
       " 6405,\n",
       " 607,\n",
       " 438,\n",
       " 20777,\n",
       " 339,\n",
       " 8288,\n",
       " 465,\n",
       " 10152,\n",
       " 438,\n",
       " 13893,\n",
       " 339,\n",
       " 1422,\n",
       " 470,\n",
       " 765,\n",
       " 284,\n",
       " 467,\n",
       " 319,\n",
       " 12036,\n",
       " 26,\n",
       " 475,\n",
       " 340,\n",
       " 561,\n",
       " 423,\n",
       " 587,\n",
       " 1327,\n",
       " 284,\n",
       " 5879,\n",
       " 326,\n",
       " 339,\n",
       " 550,\n",
       " 1813,\n",
       " 510,\n",
       " 465,\n",
       " 12036,\n",
       " 780,\n",
       " 339,\n",
       " 550,\n",
       " 6405,\n",
       " 607,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 5189,\n",
       " 1781,\n",
       " 11,\n",
       " 611,\n",
       " 673,\n",
       " 550,\n",
       " 407,\n",
       " 17901,\n",
       " 683,\n",
       " 866,\n",
       " 11,\n",
       " 673,\n",
       " 550,\n",
       " 8603,\n",
       " 11,\n",
       " 355,\n",
       " 4544,\n",
       " 9325,\n",
       " 701,\n",
       " 42397,\n",
       " 11,\n",
       " 4054,\n",
       " 284,\n",
       " 366,\n",
       " 26282,\n",
       " 683,\n",
       " 510,\n",
       " 1,\n",
       " 438,\n",
       " 7091,\n",
       " 550,\n",
       " 407,\n",
       " 2957,\n",
       " 683,\n",
       " 736,\n",
       " 284,\n",
       " 262,\n",
       " 1396,\n",
       " 417,\n",
       " 13,\n",
       " 1675,\n",
       " 1234,\n",
       " 262,\n",
       " 14093,\n",
       " 656,\n",
       " 465,\n",
       " 1021,\n",
       " 757,\n",
       " 438,\n",
       " 10919,\n",
       " 257,\n",
       " 410,\n",
       " 5040,\n",
       " 329,\n",
       " 257,\n",
       " 3656,\n",
       " 0,\n",
       " 887,\n",
       " 9074,\n",
       " 13,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 4120,\n",
       " 284,\n",
       " 423,\n",
       " 595,\n",
       " 67,\n",
       " 1328,\n",
       " 340,\n",
       " 438,\n",
       " 392,\n",
       " 314,\n",
       " 2936,\n",
       " 340,\n",
       " 1244,\n",
       " 307,\n",
       " 3499,\n",
       " 284,\n",
       " 1064,\n",
       " 503,\n",
       " 1521,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 464,\n",
       " 748,\n",
       " 586,\n",
       " 652,\n",
       " 1204,\n",
       " 286,\n",
       " 262,\n",
       " 34686,\n",
       " 41976,\n",
       " 37733,\n",
       " 2346,\n",
       " 284,\n",
       " 884,\n",
       " 14177,\n",
       " 8233,\n",
       " 1020,\n",
       " 5768,\n",
       " 26,\n",
       " 290,\n",
       " 1719,\n",
       " 11,\n",
       " 319,\n",
       " 616,\n",
       " 835,\n",
       " 284,\n",
       " 22489,\n",
       " 40089,\n",
       " 11,\n",
       " 4978,\n",
       " 257,\n",
       " 19350,\n",
       " 286,\n",
       " 3619,\n",
       " 338,\n",
       " 3652,\n",
       " 436,\n",
       " 81,\n",
       " 5286,\n",
       " 8812,\n",
       " 2114,\n",
       " 1022,\n",
       " 262,\n",
       " 279,\n",
       " 1127,\n",
       " 11,\n",
       " 314,\n",
       " 550,\n",
       " 3589,\n",
       " 28068,\n",
       " 294,\n",
       " 1555,\n",
       " 262,\n",
       " 1306,\n",
       " 1110,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 40,\n",
       " 1043,\n",
       " 262,\n",
       " 3155,\n",
       " 379,\n",
       " 8887,\n",
       " 11061,\n",
       " 511,\n",
       " 18057,\n",
       " 12,\n",
       " 83,\n",
       " 6037,\n",
       " 26,\n",
       " 290,\n",
       " 9074,\n",
       " 13,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 338,\n",
       " 7062,\n",
       " 373,\n",
       " 523,\n",
       " 2429,\n",
       " 498,\n",
       " 326,\n",
       " 11,\n",
       " 287,\n",
       " 262,\n",
       " 29543,\n",
       " 2745,\n",
       " 11,\n",
       " 314,\n",
       " 4752,\n",
       " 340,\n",
       " 6777,\n",
       " 13,\n",
       " 632,\n",
       " 373,\n",
       " 407,\n",
       " 326,\n",
       " 616,\n",
       " 2583,\n",
       " 408,\n",
       " 373,\n",
       " 366,\n",
       " 47914,\n",
       " 1298,\n",
       " 319,\n",
       " 326,\n",
       " 966,\n",
       " 314,\n",
       " 714,\n",
       " 423,\n",
       " 1813,\n",
       " 4544,\n",
       " 9325,\n",
       " 701,\n",
       " 262,\n",
       " 40830,\n",
       " 12719,\n",
       " 3874,\n",
       " 13,\n",
       " 632,\n",
       " 373,\n",
       " 655,\n",
       " 780,\n",
       " 673,\n",
       " 373,\n",
       " 4808,\n",
       " 1662,\n",
       " 62,\n",
       " 3499,\n",
       " 438,\n",
       " 361,\n",
       " 314,\n",
       " 743,\n",
       " 307,\n",
       " 41746,\n",
       " 12004,\n",
       " 262,\n",
       " 6473,\n",
       " 438,\n",
       " 5562,\n",
       " 314,\n",
       " 1043,\n",
       " 607,\n",
       " 523,\n",
       " 13,\n",
       " 1114,\n",
       " 3619,\n",
       " 11,\n",
       " 477,\n",
       " 465,\n",
       " 1204,\n",
       " 11,\n",
       " 550,\n",
       " 587,\n",
       " 11191,\n",
       " 416,\n",
       " 3499,\n",
       " 1466,\n",
       " 25,\n",
       " 484,\n",
       " 550,\n",
       " 26546,\n",
       " 1068,\n",
       " 465,\n",
       " 1242,\n",
       " 11,\n",
       " 340,\n",
       " 550,\n",
       " 587,\n",
       " 302,\n",
       " 1144,\n",
       " 287,\n",
       " 262,\n",
       " 3024,\n",
       " 12,\n",
       " 4803,\n",
       " 286,\n",
       " 511,\n",
       " 512,\n",
       " 1741,\n",
       " 13,\n",
       " 843,\n",
       " 340,\n",
       " 373,\n",
       " 4361,\n",
       " 5048,\n",
       " 425,\n",
       " 284,\n",
       " 3465,\n",
       " 644,\n",
       " 1245,\n",
       " 262,\n",
       " 366,\n",
       " 25124,\n",
       " 3101,\n",
       " 8137,\n",
       " 286,\n",
       " 16957,\n",
       " 1696,\n",
       " 414,\n",
       " 1,\n",
       " 357,\n",
       " 40,\n",
       " 9577,\n",
       " 4544,\n",
       " 9325,\n",
       " 701,\n",
       " 8,\n",
       " 373,\n",
       " 1719,\n",
       " 319,\n",
       " 683,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 40,\n",
       " 423,\n",
       " 4750,\n",
       " 326,\n",
       " 9074,\n",
       " 13,\n",
       " 402,\n",
       " 271,\n",
       " 10899,\n",
       " 373,\n",
       " 5527,\n",
       " 26,\n",
       " 290,\n",
       " 340,\n",
       " 373,\n",
       " 3393,\n",
       " 34953,\n",
       " 856,\n",
       " 326,\n",
       " 607,\n",
       " 5229,\n",
       " 373,\n",
       " 37895,\n",
       " 422,\n",
       " 428,\n",
       " 25179,\n",
       " 257,\n",
       " 19217,\n",
       " 475,\n",
       " 8904,\n",
       " 14676,\n",
       " 13,\n",
       " 632,\n",
       " 318,\n",
       " 11,\n",
       " 355,\n",
       " 257,\n",
       " 3896,\n",
       " 11,\n",
       " 262,\n",
       " 661,\n",
       " 508,\n",
       " 40987,\n",
       " 1637,\n",
       " 508,\n",
       " 651,\n",
       " 749,\n",
       " 503,\n",
       " 286,\n",
       " 340,\n",
       " 26,\n",
       " 290,\n",
       " 3619,\n",
       " 338,\n",
       " 19992,\n",
       " 31564,\n",
       " 286,\n",
       " 465,\n",
       " 3656,\n",
       " 338,\n",
       " 1263,\n",
       " 5236,\n",
       " 9343,\n",
       " 683,\n",
       " 11,\n",
       " 351,\n",
       " 281,\n",
       " 5585,\n",
       " 286,\n",
       " 2818,\n",
       " 922,\n",
       " 12,\n",
       " 49705,\n",
       " 11,\n",
       " 284,\n",
       " 21595,\n",
       " 1133,\n",
       " 340,\n",
       " 656,\n",
       " 5563,\n",
       " 286,\n",
       " 1242,\n",
       " 290,\n",
       " 13064,\n",
       " 13,\n",
       " 1675,\n",
       " 262,\n",
       " 6846,\n",
       " 11,\n",
       " 314,\n",
       " 1276,\n",
       " 751,\n",
       " 11,\n",
       " 339,\n",
       " 6150,\n",
       " 5365,\n",
       " 31655,\n",
       " 26,\n",
       " 475,\n",
       " 339,\n",
       " 373,\n",
       " 7067,\n",
       " 29396,\n",
       " 18443,\n",
       " 12271,\n",
       " 290,\n",
       " 45592,\n",
       " 12,\n",
       " 14792,\n",
       " 5986,\n",
       " 351,\n",
       " 257,\n",
       " 8839,\n",
       " 326,\n",
       " 7284,\n",
       " 35924,\n",
       " 262,\n",
       " 12306,\n",
       " 395,\n",
       " 4133,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 1,\n",
       " 26788,\n",
       " 338,\n",
       " 691,\n",
       " 12226,\n",
       " 318,\n",
       " 284,\n",
       " 1234,\n",
       " 8737,\n",
       " 656,\n",
       " 19133,\n",
       " 553,\n",
       " 373,\n",
       " 530,\n",
       " 286,\n",
       " 262,\n",
       " 7877,\n",
       " 72,\n",
       " 3150,\n",
       " 339,\n",
       " 8104,\n",
       " 866,\n",
       " 1973,\n",
       " 262,\n",
       " 37918,\n",
       " 411,\n",
       " 290,\n",
       " 8465,\n",
       " 286,\n",
       " 281,\n",
       " 33954,\n",
       " 271,\n",
       " ...]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_sample = enc_text[50:]\n",
    "enc_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df6d4979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5095\n"
     ]
    }
   ],
   "source": [
    "print(len(enc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a1f660c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([290, 4920, 2241, 287], [4920, 2241, 287, 257])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_sample[:4], enc_sample[1:4+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f10c25",
   "metadata": {},
   "source": [
    "One of the easiest and most intuitive ways to create the `input-target` pairs for the next-word prediction task is to create two variables, `x` and `y`, where `x` contains the `input` tokens and `y` contains the `targets`, which are the inputs shifted by `1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c49d0335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y:       [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "# The context size determines how many tokens are included in the input\n",
    "context_size = 4\n",
    "\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y:       {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03623f34",
   "metadata": {},
   "source": [
    "Processing the inputs along with the targets, which are the inputs shifted by one position, we can then create the next-word prediction tasks depicted earlier.\n",
    "\n",
    "- One by one, the prediction would look like as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "913f5661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    \n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b5910",
   "metadata": {},
   "source": [
    "Everything left of the arrow `(---->)` refers to the input an LLM would receive, and the token ID on the right side of the arrow represents the target token ID that the LLM is supposed to predict.\n",
    "\n",
    "Let's repeat the previous code but convert the `token IDs` into text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4b555900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and --->  established\n",
      " and established --->  himself\n",
      " and established himself --->  in\n",
      " and established himself in --->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(tokenizer.decode(context), \"--->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbc2d86",
   "metadata": {},
   "source": [
    "There's only one more task before we can turn the tokens into embeddings, as we mentioned earlier: implementing an efficient `data loader` that iterates over the input dataset and returns the `inputs` and `targets` as PyTorch tensors, which can be thought of as `multidimensional arrays`.\n",
    "\n",
    "\n",
    "In particular, we are interested in returning two tensors: an `input tensor` containing the text that the LLM sees and a `target tensor` that includes the targets for the LLM to predict, as depicted in the diagram below;\n",
    "\n",
    "\n",
    "![Alt text](../../assests/data-loaders.png)\n",
    "\n",
    "\n",
    "To implement efficient `data loaders`, we collect the inputs in a tensor, `x`, where each row represents one input context. A second tensor, `y`, contains the corresponding prediction targets (next words), which are created by shifting the input by one position.\n",
    "\n",
    "The code implementation will operate on token IDs directly since the `encode` method of the `BPE` tokenizer performs both tokenization and conversion into token IDs as a single step. \n",
    "\n",
    "For the efficient `data loader` implementation, we will use PyTorch's built-in Dataset and DataLoader classes.\n",
    "\n",
    "- Create dataset and dataloader that extract chunks from the input text dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8327e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "        \n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "        \n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    \n",
    "    # Return the total number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    # Return a single row from the dataset\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8fa640",
   "metadata": {},
   "source": [
    "The `GPTDatasetV1` class is based on the PyTorch `Dataset` class and defines how individual rows are fetched from the dataset, where each row consists of a number of token IDs (based on a `max_length`) assigned to an `input_chunk` tensor. The `target_chunk` tensor contains the corresponding targets. \n",
    "\n",
    "\n",
    "The class creates training examples by sliding a fixed-size window through text, where each input sequence is paired with a target sequence that's shifted by one token (predicting the next token). It efficiently generates training examples from a single text.\n",
    "\n",
    "**Purpose:**\n",
    "Creates input-target pairs for next-token prediction training.\n",
    "\n",
    "**Key Components:**\n",
    "1. `__init__` method:\n",
    "\n",
    "    - `txt`: Raw text to process\n",
    "    - `tokenizer`: Converts text to token IDs\n",
    "    - `max_length`: Size of each input sequence\n",
    "    - `stride`: How many tokens to move the window each step\n",
    "\n",
    "\n",
    "2. `Sliding Window Process:`\n",
    "```py\n",
    "# Example: \"The cat sat on the mat\" with max_length=3, stride=2\n",
    "# Window 1: Input=[\"The\", \"cat\", \"sat\"]  Target=[\"cat\", \"sat\", \"on\"]\n",
    "# Window 2: Input=[\"sat\", \"on\", \"the\"]  Target=[\"on\", \"the\", \"mat\"]\n",
    "# etc.\n",
    "```\n",
    "\n",
    "\n",
    "3. `Input-Target Relationship:`\n",
    "    - For each position `i`, the target is always the next token in the sequence.\n",
    "    - This teaches the model: \"Given these tokens, predict what comes next\"\n",
    "\n",
    "\n",
    "**How it Works:**\n",
    "- `Tokenizes` the entire text once.\n",
    "- `Slides a window` through the tokens with specified stride\n",
    "- `Creates pairs` where target is input shifted by 1 position.\n",
    "- `Stores` all pairs as tensors for efficient training.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34c5181",
   "metadata": {},
   "source": [
    "The following code will use the `GPTDatasetV1` to load the inputs in batches via a `PyTorch DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "62951f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, \n",
    "                         stride=128, shuffle=True, \n",
    "                         drop_last=True, num_workers=0):\n",
    "    \n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    \n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7907a6e5",
   "metadata": {},
   "source": [
    "- `drop_last=True` drops the last batch if it is shorter than the specified batch_size to prevent loss spikes during training.\n",
    "- `num_workers` The number of CPU processes to use for preprocessing.\n",
    "\n",
    "\n",
    "Let's test the dataloader with a batch size of 1 for an LLM with a context size of 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "25c2ed45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "# A convert dataloader into a Python iterator to fetch the next entry via Python's built-in next() function\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8205b9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "#     batch = next(data_iter)\n",
    "#     print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "488cd10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\\n\\n\"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it\\'s going to send the value of my picture \\'way up; but I don\\'t think of that, Mr. Rickham--the loss to Arrt is all I think of.\" The word, on Mrs. Thwing\\'s lips, multiplied its _rs_ as though they were reflected in an endless vista of mirrors. And it was not only the Mrs. Thwings who mourned. Had not the exquisite Hermia Croft, at the last Grafton Gallery show, stopped me before Gisburn\\'s \"Moon-dancers\" to say, with tears in her eyes: \"We shall not look upon its like again\"?\\n\\nWell!--even through the prism of Hermia\\'s tears I felt able to face the fact with equanimity. Poor Jack Gisburn! The women had made him--it was fitting that they should mourn him. Among his own sex fewer regrets were heard, and in his own trade hardly a murmur. Professional jealousy? Perhaps. If it were, the honour of the craft was vindicated by little Claude Nutley, who, in all good faith, brought out in the Burlington a very handsome \"obituary\" on Jack--one of those showy articles stocked with random technicalities that I have heard (I won\\'t say by whom) compared to Gisburn\\'s painting. And so--his resolve being apparently irrevocable--the discussion gradually died out, and, as Mrs. Thwing had predicted, the price of \"Gisburns\" went up.\\n\\nIt was not till three years later that, in the course of a few weeks\\' idling on the Riviera, it suddenly occurred to me to wonder why Gisburn had given up his painting. On reflection, it really was a tempting problem. To accuse his wife would have been too easy--his fair sitters had been denied the solace of saying that Mrs. Gisburn had \"dragged him down.\" For Mrs. Gisburn--as such--had not existed till nearly a year after Jack\\'s resolve had been taken. It might be that he had married her--since he liked his ease--because he didn\\'t want to go on painting; but it would have been hard to prove that he had given up his painting because he had married her.\\n\\nOf course, if she had not dragged him down, she had equally, as Miss Croft contended, failed to \"lift him up\"--she had not led him back to the easel. To put the brush into his hand again--what a vocation for a wife! But Mrs. Gisburn appeared to have disdained it--and I felt it might be interesting to find out why.\\n\\nThe desultory life of the Riviera lends itself to such purely academic speculations; and having, on my way to Monte Carlo, caught a glimpse of Jack\\'s balustraded terraces between the pines, I had myself borne thither the next day.\\n\\nI found the couple at tea beneath their palm-trees; and Mrs. Gisburn\\'s welcome was so genial that, in the ensuing weeks, I claimed it frequently. It was not that my hostess was \"interesting\": on that point I could have given Miss Croft the fullest reassurance. It was just because she was _not_ interesting--if I may be pardoned the bull--that I found her so. For Jack, all his life, had been surrounded by interesting women: they had fostered his art, it had been reared in the hot-house of their adulation. And it was therefore instructive to note what effect the \"deadening atmosphere of mediocrity\" (I quote Miss Croft) was having on him.\\n\\nI have mentioned that Mrs. Gisburn was rich; and it was immediately perceptible that her husband was extracting from this circumstance a delicate but substantial satisfaction. It is, as a rule, the people who scorn money who get most out of it; and Jack\\'s elegant disdain of his wife\\'s big balance enabled him, with an appearance of perfect good-breeding, to transmute it into objects of art and luxury. To the latter, I must add, he remained relatively indifferent; but he was buying Renaissance bronzes and eighteenth-century pictures with a discrimination that bespoke the amplest resources.\\n\\n\"Money\\'s only excuse is to put beauty into circulation,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gisburn, beaming on him, added for my enlightenment: \"Jack is so morbidly sensitive to every form of beauty.\"\\n\\nPoor Jack! It had always been his fate to have women say such things of him: the fact should be set down in extenuation. What struck me now was that, for the first time, he resented the tone. I had seen him, so often, basking under similar tributes--was it the conjugal note that robbed them of their savour? No--for, oddly enough, it became apparent that he was fond of Mrs. Gisburn--fond enough not to see her absurdity. It was his own absurdity he seemed to be wincing under--his own attitude as an object for garlands and incense.\\n\\n\"My dear, since I\\'ve chucked painting people don\\'t say that stuff about me--they say it about Victor Grindle,\" was his only protest, as he rose from the table and strolled out onto the sunlit terrace.\\n\\nI glanced after him, struck by his last word. Victor Grindle was, in fact, becoming the man of the moment--as Jack himself, one might put it, had been the man of the hour. The younger artist was said to have formed himself at my friend\\'s feet, and I wondered if a tinge of jealousy underlay the latter\\'s mysterious abdication. But no--for it was not till after that event that the _rose Dubarry_ drawing-rooms had begun to display their \"Grindles.\"\\n\\nI turned to Mrs. Gisburn, who had lingered to give a lump of sugar to her spaniel in the dining-room.\\n\\n\"Why _has_ he chucked painting?\" I asked abruptly.\\n\\nShe raised her eyebrows with a hint of good-humoured surprise.\\n\\n\"Oh, he doesn\\'t _have_ to now, you know; and I want him to enjoy himself,\" she said quite simply.\\n\\nI looked about the spacious white-panelled room, with its _famille-verte_ vases repeating the tones of the pale damask curtains, and its eighteenth-century pastels in delicate faded frames.\\n\\n\"Has he chucked his pictures too? I haven\\'t seen a single one in the house.\"\\n\\nA slight shade of constraint crossed Mrs. Gisburn\\'s open countenance. \"It\\'s his ridiculous modesty, you know. He says they\\'re not fit to have about; he\\'s sent them all away except one--my portrait--and that I have to keep upstairs.\"\\n\\nHis ridiculous modesty--Jack\\'s modesty about his pictures? My curiosity was growing like the bean-stalk. I said persuasively to my hostess: \"I must really see your portrait, you know.\"\\n\\nShe glanced out almost timorously at the terrace where her husband, lounging in a hooded chair, had lit a cigar and drawn the Russian deerhound\\'s head between his knees.\\n\\n\"Well, come while he\\'s not looking,\" she said, with a laugh that tried to hide her nervousness; and I followed her between the marble Emperors of the hall, and up the wide stairs with terra-cotta nymphs poised among flowers at each landing.\\n\\nIn the dimmest corner of her boudoir, amid a profusion of delicate and distinguished objects, hung one of the familiar oval canvases, in the inevitable garlanded frame. The mere outline of the frame called up all Gisburn\\'s past!\\n\\nMrs. Gisburn drew back the window-curtains, moved aside a _jardiniere_ full of pink azaleas, pushed an arm-chair away, and said: \"If you stand here you can just manage to see it. I had it over the mantel-piece, but he wouldn\\'t let it stay.\"\\n\\nYes--I could just manage to see it--the first portrait of Jack\\'s I had ever had to strain my eyes over! Usually they had the place of honour--say the central panel in a pale yellow or _rose Dubarry_ drawing-room, or a monumental easel placed so that it took the light through curtains of old Venetian point. The more modest place became the picture better; yet, as my eyes grew accustomed to the half-light, all the characteristic qualities came out--all the hesitations disguised as audacities, the tricks of prestidigitation by which, with such consummate skill, he managed to divert attention from the real business of the picture to some pretty irrelevance of detail. Mrs. Gisburn, presenting a neutral surface to work on--forming, as it were, so inevitably the background of her own picture--had lent herself in an unusual degree to the display of this false virtuosity. The picture was one of Jack\\'s \"strongest,\" as his admirers would have put it--it represented, on his part, a swelling of muscles, a congesting of veins, a balancing, straddling and straining, that reminded one of the circus-clown\\'s ironic efforts to lift a feather. It met, in short, at every point the demand of lovely woman to be painted \"strongly\" because she was tired of being painted \"sweetly\"--and yet not to lose an atom of the sweetness.\\n\\n\"It\\'s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride. \"The last but one,\" she corrected herself--\"but the other doesn\\'t count, because he destroyed it.\"\\n\\n\"Destroyed it?\" I was about to follow up this clue when I heard a footstep and saw Jack himself on the threshold.\\n\\nAs he stood there, his hands in the pockets of his velveteen coat, the thin brown waves of hair pushed back from his white forehead, his lean sunburnt cheeks furrowed by a smile that lifted the tips of a self-confident moustache, I felt to what a degree he had the same quality as his pictures--the quality of looking cleverer than he was.\\n\\nHis wife glanced at him deprecatingly, but his eyes travelled past her to the portrait.\\n\\n\"Mr. Rickham wanted to see it,\" she began, as if excusing herself. He shrugged his shoulders, still smiling.\\n\\n\"Oh, Rickham found me out long ago,\" he said lightly; then, passing his arm through mine: \"Come and see the rest of the house.\"\\n\\nHe showed it to me with a kind of naive suburban pride: the bath-rooms, the speaking-tubes, the dress-closets, the trouser-presses--all the complex simplifications of the millionaire\\'s domestic economy. And whenever my wonder paid the expected tribute he said, throwing out his chest a little: \"Yes, I really don\\'t see how people manage to live without that.\"\\n\\nWell--it was just the end one might have foreseen for him. Only he was, through it all and in spite of it all--as he had been through, and in spite of, his pictures--so handsome, so charming, so disarming, that one longed to cry out: \"Be dissatisfied with your leisure!\" as once one had longed to say: \"Be dissatisfied with your work!\"\\n\\nBut, with the cry on my lips, my diagnosis suffered an unexpected check.\\n\\n\"This is my own lair,\" he said, leading me into a dark plain room at the end of the florid vista. It was square and brown and leathery: no \"effects\"; no bric-a-brac, none of the air of posing for reproduction in a picture weekly--above all, no least sign of ever having been used as a studio.\\n\\nThe fact brought home to me the absolute finality of Jack\\'s break with his old life.\\n\\n\"Don\\'t you ever dabble with paint any more?\" I asked, still looking about for a trace of such activity.\\n\\n\"Never,\" he said briefly.\\n\\n\"Or water-colour--or etching?\"\\n\\nHis confident eyes grew dim, and his cheeks paled a little under their handsome sunburn.\\n\\n\"Never think of it, my dear fellow--any more than if I\\'d never touched a brush.\"\\n\\nAnd his tone told me in a flash that he never thought of anything else.\\n\\nI moved away, instinctively embarrassed by my unexpected discovery; and as I turned, my eye fell on a small picture above the mantel-piece--the only object breaking the plain oak panelling of the room.\\n\\n\"Oh, by Jove!\" I said.\\n\\nIt was a sketch of a donkey--an old tired donkey, standing in the rain under a wall.\\n\\n\"By Jove--a Stroud!\" I cried.\\n\\nHe was silent; but I felt him close behind me, breathing a little quickly.\\n\\n\"What a wonder! Made with a dozen lines--but on everlasting foundations. You lucky chap, where did you get it?\"\\n\\nHe answered slowly: \"Mrs. Stroud gave it to me.\"\\n\\n\"Ah--I didn\\'t know you even knew the Strouds. He was such an inflexible hermit.\"\\n\\n\"I didn\\'t--till after. . . . She sent for me to paint him when he was dead.\"\\n\\n\"When he was dead? You?\"\\n\\nI must have let a little too much amazement escape through my surprise, for he answered with a deprecating laugh: \"Yes--she\\'s an awful simpleton, you know, Mrs. Stroud. Her only idea was to have him done by a fashionable painter--ah, poor Stroud! She thought it the surest way of proclaiming his greatness--of forcing it on a purblind public. And at the moment I was _the_ fashionable painter.\"\\n\\n\"Ah, poor Stroud--as you say. Was _that_ his history?\"\\n\\n\"That was his history. She believed in him, gloried in him--or thought she did. But she couldn\\'t bear not to have all the drawing-rooms with her. She couldn\\'t bear the fact that, on varnishing days, one could always get near enough to see his pictures. Poor woman! She\\'s just a fragment groping for other fragments. Stroud is the only whole I ever knew.\"\\n\\n\"You ever knew? But you just said--\"\\n\\nGisburn had a curious smile in his eyes.\\n\\n\"Oh, I knew him, and he knew me--only it happened after he was dead.\"\\n\\nI dropped my voice instinctively. \"When she sent for you?\"\\n\\n\"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\\n\\nHe laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I couldn\\'t look at that thing--couldn\\'t face it. But I forced myself to put it here; and now it\\'s cured me--cured me. That\\'s the reason why I don\\'t dabble any more, my dear Rickham; or rather Stroud himself is the reason.\"\\n\\nFor the first time my idle curiosity about my companion turned into a serious desire to understand him better.\\n\\n\"I wish you\\'d tell me how it happened,\" I said.\\n\\nHe stood looking up at the sketch, and twirling between his fingers a cigarette he had forgotten to light. Suddenly he turned toward me.\\n\\n\"I\\'d rather like to tell you--because I\\'ve always suspected you of loathing my work.\"\\n\\nI made a deprecating gesture, which he negatived with a good-humoured shrug.\\n\\n\"Oh, I didn\\'t care a straw when I believed in myself--and now it\\'s an added tie between us!\"\\n\\nHe laughed slightly, without bitterness, and pushed one of the deep arm-chairs forward. \"There: make yourself comfortable--and here are the cigars you like.\"\\n\\nHe placed them at my elbow and continued to wander up and down the room, stopping now and then beneath the picture.\\n\\n\"How it happened? I can tell you in five minutes--and it didn\\'t take much longer to happen. . . . I can remember now how surprised and pleased I was when I got Mrs. Stroud\\'s note. Of course, deep down, I had always _felt_ there was no one like him--only I had gone with the stream, echoed the usual platitudes about him, till I half got to think he was a failure, one of the kind that are left behind. By Jove, and he _was_ left behind--because he had come to stay! The rest of us had to let ourselves be swept along or go under, but he was high above the current--on everlasting foundations, as you say.\\n\\n\"Well, I went off to the house in my most egregious mood--rather moved, Lord forgive me, at the pathos of poor Stroud\\'s career of failure being crowned by the glory of my painting him! Of course I meant to do the picture for nothing--I told Mrs. Stroud so when she began to stammer something about her poverty. I remember getting off a prodigious phrase about the honour being _mine_--oh, I was princely, my dear Rickham! I was posing to myself like one of my own sitters.\\n\\n\"Then I was taken up and left alone with him. I had sent all my traps in advance, and I had only to set up the easel and get to work. He had been dead only twenty-four hours, and he died suddenly, of heart disease, so that there had been no preliminary work of destruction--his face was clear and untouched. I had met him once or twice, years before, and thought him insignificant and dingy. Now I saw that he was superb.\\n\\n\"I was glad at first, with a merely aesthetic satisfaction: glad to have my hand on such a \\'subject.\\' Then his strange life-likeness began to affect me queerly--as I blocked the head in I felt as if he were watching me do it. The sensation was followed by the thought: if he _were_ watching me, what would he say to my way of working? My strokes began to go a little wild--I felt nervous and uncertain.\\n\\n\"Once, when I looked up, I seemed to see a smile behind his close grayish beard--as if he had the secret, and were amusing himself by holding it back from me. That exasperated me still more. The secret? Why, I had a secret worth twenty of his! I dashed at the canvas furiously, and tried some of my bravura tricks. But they failed me, they crumbled. I saw that he wasn\\'t watching the showy bits--I couldn\\'t distract his attention; he just kept his eyes on the hard passages between. Those were the ones I had always shirked, or covered up with some lying paint. And how he saw through my lies!\\n\\n\"I looked up again, and caught sight of that sketch of the donkey hanging on the wall near his bed. His wife told me afterward it was the last thing he had done--just a note taken with a shaking hand, when he was down in Devonshire recovering from a previous heart attack. Just a note! But it tells his whole history. There are years of patient scornful persistence in every line. A man who had swum with the current could never have learned that mighty up-stream stroke. . . .\\n\\n\"I turned back to my work, and went on groping and muddling; then I looked at the donkey again. I saw that, when Stroud laid in the first stroke, he knew just what the end would be. He had possessed his subject, absorbed it, recreated it. When had I done that with any of my things? They hadn\\'t been born of me--I had just adopted them. . . .\\n\\n\"Hang it, Rickham, with that face watching me I couldn\\'t do another stroke. The plain truth was, I didn\\'t know where to put it--_I had never known_. Only, with my sitters and my public, a showy splash of colour covered up the fact--I just threw paint into their faces. . . . Well, paint was the one medium those dead eyes could see through--see straight to the tottering foundations underneath. Don\\'t you know how, in talking a foreign language, even fluently, one says half the time not what one wants to but what one can? Well--that was the way I painted; and as he lay there and watched me, the thing they called my \\'technique\\' collapsed like a house of cards. He didn\\'t sneer, you understand, poor Stroud--he just lay there quietly watching, and on his lips, through the gray beard, I seemed to hear the question: \\'Are you sure you know where you\\'re coming out?\\'\\n\\n\"If I could have painted that face, with that question on it, I should have done a great thing. The next greatest thing was to see that I couldn\\'t--and that grace was given me. But, oh, at that minute, Rickham, was there anything on earth I wouldn\\'t have given to have Stroud alive before me, and to hear him say: \\'It\\'s not too late--I\\'ll show you how\\'?\\n\\n\"It _was_ too late--it would have been, even if he\\'d been alive. I packed up my traps, and went down and told Mrs. Stroud. Of course I didn\\'t tell her _that_--it would have been Greek to her. I simply said I couldn\\'t paint him, that I was too moved. She rather liked the idea--she\\'s so romantic! It was that that made her give me the donkey. But she was terribly upset at not getting the portrait--she did so want him \\'done\\' by some one showy! At first I was afraid she wouldn\\'t let me off--and at my wits\\' end I suggested Grindle. Yes, it was I who started Grindle: I told Mrs. Stroud he was the \\'coming\\' man, and she told somebody else, and so it got to be true. . . . And he painted Stroud without wincing; and she hung the picture among her husband\\'s things. . . .\"\\n\\nHe flung himself down in the arm-chair near mine, laid back his head, and clasping his arms beneath it, looked up at the picture above the chimney-piece.\\n\\n\"I like to fancy that Stroud himself would have given it to me, if he\\'d been able to say what he thought that day.\"\\n\\nAnd, in answer to a question I put half-mechanically--\"Begin again?\" he flashed out. \"When the one thing that brings me anywhere near him is that I knew enough to leave off?\"\\n\\nHe stood up and laid his hand on my shoulder with a laugh. \"Only the irony of it is that I _am_ still painting--since Grindle\\'s doing it for me! The Strouds stand alone, and happen once--but there\\'s no exterminating our kind of art.\"'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b279fce",
   "metadata": {},
   "source": [
    "The `first_batch` variable contains two tensors: the first tensor stores the input token IDs, and the second tensor stores the target token IDs. Since the `max_length` is set to `4`, each of the two tensors contains `4` token IDs. \n",
    "\n",
    "Note that an input size of `4` is relatively small and only chosen for illustration purposes. It is common to train LLMs with input sizes of at least `256`.\n",
    "\n",
    "To illustrate the meaning of `stride=1`, let's fetch another batch from this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "80bfb770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 367, 2885, 1464, 1807]]), tensor([[2885, 1464, 1807, 3619]])]\n"
     ]
    }
   ],
   "source": [
    "second_batch = next(data_iter)\n",
    "print(second_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c860b1",
   "metadata": {},
   "source": [
    "If we compare the `first` with the `second` batch, we can see that the second batch's token IDs are shifted by one position compared to the first batch (for example, the second ID in the first batch's input is `367`, which is the first ID of the second batch's input). The stride setting dictates the number of positions the inputs shift across batches, emulating a sliding window approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75f2b3",
   "metadata": {},
   "source": [
    "- We can also create batched outputs.\n",
    "- Note that we increase the stride here so that we don't have overlaps between the batches, since more overlap could lead to increased overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "30346766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Inputs:\\n\", inputs)\n",
    "print(\"\\nTargets:\\n\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d64d094",
   "metadata": {},
   "source": [
    "Note that we increase the stride to `4`. This is to utilize the data set fully (we don't skip a single word) but also avoid any overlap between the batches, since more overlap could lead to increased overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9868756",
   "metadata": {},
   "source": [
    "## Creating token embeddings\n",
    "\n",
    "The last step for preparing the input text for LLM training is to convert the token IDs into `embedding vectors`.\n",
    "\n",
    "![Alt text](../../assests/embedding-vectors.png)\n",
    "\n",
    "Preparing the input text for an LLM involves `tokenizing text`, `converting text tokens` to `token IDs`, and converting token IDs into `vector embedding vectors`. In this section, we consider the token IDs created in the previous sections to create the token embedding vectors.\n",
    "\n",
    "It is important to note that we initiallize these embedding weights with random values as a preliminary step. This initialization serves as the starting point for the LLM's learning process.\n",
    "\n",
    "A continuous vector representation, or embedding, is necessary since GPT-like LLMs are deep neural networks trained with the backpropagation algorithm. \n",
    "\n",
    "\n",
    "- The data is already almost ready for an LLM.\n",
    "- But lastly let us embed the tokens in a continuous vector representation using an embedding layer.\n",
    "- Usually, these embedding layers are part of the LLM itself and are updated (trained) during model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4606d2",
   "metadata": {},
   "source": [
    "Suppose we have the following four input examples with input ids 2, 3, 5, and 1 (after tokenization):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ede2d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd56e93",
   "metadata": {},
   "source": [
    "For the sake of simplicity, suppose we have a small vocabulary of only `6` words and we want to create embeddings of size `3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7e6ccda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e4d8b",
   "metadata": {},
   "source": [
    "This would result in a 6x3 weight matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "940a29b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "63bb0bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db119ef0",
   "metadata": {},
   "source": [
    "We can see that the weight matrix has six rows and three columns. There is one row for each of the six possible tokens in the vocabulary. And there is one column for each of the three embedding dimensions.\n",
    "\n",
    "\n",
    "- For those who are familiar with `one-hot encoding`, the `embedding layer` approach above is essentially just a more efficient way of implementing one-hot encoding followed by `matrix multiplication` in a fully-connected layer.  \n",
    "\n",
    "- Because the embedding layer is just a more efficient implementation that is equivalent to the one-hot encoding and matrix-multiplication approach it can be seen as a neural network layer that can be optimized via backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5dd8e5",
   "metadata": {},
   "source": [
    "- To convert a token with id 3 into a 3-dimensional vector, we do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fe034bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b908c6",
   "metadata": {},
   "source": [
    "- Note that the above is the 4th row in the embedding_layer weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aa6f378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9178, 1.5810, 1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27affd43",
   "metadata": {},
   "source": [
    "- To embed all four input_ids values above, we do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a668478e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cccb7c",
   "metadata": {},
   "source": [
    "- Each row in this output matrix is obtained via a lookup operation from the embedding weight matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968e5a87",
   "metadata": {},
   "source": [
    "## Encoding word positions\n",
    "\n",
    "In the previous section, we converted the token IDs into a continuous vector representation, the so-called token embeddings. In principle, this is a suitable input for an LLM. However, a minor shortcoming of LLMs is that their `self-attention` mechanism, doesn't have a notion of position or order for the tokens within a sequence.\n",
    "\n",
    "\n",
    "- Embedding layer convert IDs into identical vector representations regardless of where they are located in the input sequence:\n",
    "\n",
    "![Alt text](../../assests/token-IDs-embedding.png)\n",
    "\n",
    "\n",
    "In principle, the deterministic, position-independent embedding of the token ID is good for reproducibility purposes. However, since the self-attention mechanism of LLMs itself is also position-agnostic, it is helpful to inject additional position information into the LLM.\n",
    "\n",
    "Absolute positional embeddings are directly associated with specific positions in a sequence. For each position in the input sequence, a unique embedding is added to the token's embedding to convey its exact location. For instance, the first token will have a specific positional embedding, the second token another distinct embedding, and so on.\n",
    "\n",
    "\n",
    "- Positional embeddings are combined with the token embedding vector to form the input embeddings for a large language model:\n",
    "\n",
    "![Alt text](../../assests/positional-embedding.png)\n",
    "\n",
    "\n",
    "Instead of focusing on the absolute position of a token, the emphasis of relative positional embeddings is on the relative position or distance between tokens. This means the model learns the relationships in terms of \"how far apart\" rather than \"at which exact position.\" The advantage here is that the model can generalize better to sequences of varying\n",
    "lengths, even if it hasn't seen such lengths during training.\n",
    "\n",
    "\n",
    "Both types of `positional embeddings` aim to augment the capacity of LLMs to understand the order and relationships between tokens, ensuring more accurate and context-aware predictions. The choice between them often depends on the specific application and the nature of the data being processed.\n",
    "\n",
    "OpenAI's GPT models use absolute positional embeddings that are optimized during the training process rather than being fixed or predefined like the positional encodings in the original Transformer model. This optimization process is part of the model training itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f76ed",
   "metadata": {},
   "source": [
    "- The BytePair encoder has a vocabulary size of `50,257`:\n",
    "- Suppose we want to encode the input tokens into a `256-dimensional vector representation`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8f29e8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccd34b5",
   "metadata": {},
   "source": [
    "- If we sample data from the `dataloader`, we embed the tokens in each batch into a `256`-dimensional vector.\n",
    "- If we have a batch size of `8` with `4` tokens each, this results in a `8 x 4 x 256` tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5b59cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length,\n",
    "    stride=max_length, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fbfa0dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      "Inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token IDs:\\n\", inputs)\n",
    "print(\"\\nInputs shape:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1c60b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb93f4f1",
   "metadata": {},
   "source": [
    "- As we can see, the token ID tensor is 8x4-dimensional, meaning that the data batch consists of `8` text samples with `4` tokens each.\n",
    "\n",
    "- Let's now use the embedding layer to embed these token IDs into 256-dimensional vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b132c252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "079e2328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.4913,  1.1239,  1.4588,  ..., -0.3995, -1.8735, -0.1445],\n",
      "         [ 0.4481,  0.2536, -0.2655,  ...,  0.4997, -1.1991, -1.1844],\n",
      "         [-0.2507, -0.0546,  0.6687,  ...,  0.9618,  2.3737, -0.0528],\n",
      "         [ 0.9457,  0.8657,  1.6191,  ..., -0.4544, -0.7460,  0.3483]],\n",
      "\n",
      "        [[ 1.5460,  1.7368, -0.7848,  ..., -0.1004,  0.8584, -0.3421],\n",
      "         [-1.8622, -0.1914, -0.3812,  ...,  1.1220, -0.3496,  0.6091],\n",
      "         [ 1.9847, -0.6483, -0.1415,  ..., -0.3841, -0.9355,  1.4478],\n",
      "         [ 0.9647,  1.2974, -1.6207,  ...,  1.1463,  1.5797,  0.3969]],\n",
      "\n",
      "        [[-0.7713,  0.6572,  0.1663,  ..., -0.8044,  0.0542,  0.7426],\n",
      "         [ 0.8046,  0.5047,  1.2922,  ...,  1.4648,  0.4097,  0.3205],\n",
      "         [ 0.0795, -1.7636,  0.5750,  ...,  2.1823,  1.8231, -0.3635],\n",
      "         [ 0.4267, -0.0647,  0.5686,  ..., -0.5209,  1.3065,  0.8473]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.6156,  0.9610, -2.6437,  ..., -0.9645,  1.0888,  1.6383],\n",
      "         [-0.3985, -0.9235, -1.3163,  ..., -1.1582, -1.1314,  0.9747],\n",
      "         [ 0.6089,  0.5329,  0.1980,  ..., -0.6333, -1.1023,  1.6292],\n",
      "         [ 0.3677, -0.1701, -1.3787,  ...,  0.7048,  0.5028, -0.0573]],\n",
      "\n",
      "        [[-0.1279,  0.6154,  1.7173,  ...,  0.3789, -0.4752,  1.5258],\n",
      "         [ 0.4861, -1.7105,  0.4416,  ...,  0.1475, -1.8394,  1.8755],\n",
      "         [-0.9573,  0.7007,  1.3579,  ...,  1.9378, -1.9052, -1.1816],\n",
      "         [ 0.2002, -0.7605, -1.5170,  ..., -0.0305, -0.3656, -0.1398]],\n",
      "\n",
      "        [[-0.9573,  0.7007,  1.3579,  ...,  1.9378, -1.9052, -1.1816],\n",
      "         [-0.0632, -0.6548, -1.0296,  ..., -0.9538, -0.5026, -0.1128],\n",
      "         [ 0.6032,  0.8983,  2.0722,  ...,  1.5242,  0.2030, -0.3002],\n",
      "         [ 1.1274, -0.1082, -0.2195,  ...,  0.5059, -1.8138, -0.0700]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(token_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d922a6",
   "metadata": {},
   "source": [
    "- For a GPT model's absolute embedding approach, we just need to create another embedding layer that has the same dimension as the `token_embedding_layer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dfd2bd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6303, -0.4848, -0.1366,  ...,  1.0345, -0.5012,  1.1045],\n",
      "        [ 0.2062,  0.6078,  0.7187,  ..., -0.4628, -0.2319,  1.1980],\n",
      "        [ 0.5806, -1.3846,  0.3266,  ...,  0.8579,  0.5059,  1.0243],\n",
      "        [ 1.4323,  0.2217,  0.8599,  ...,  0.4827,  0.8459,  1.3038]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "print(pos_embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a3473f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n",
      "tensor([[-0.6303, -0.4848, -0.1366,  ...,  1.0345, -0.5012,  1.1045],\n",
      "        [ 0.2062,  0.6078,  0.7187,  ..., -0.4628, -0.2319,  1.1980],\n",
      "        [ 0.5806, -1.3846,  0.3266,  ...,  0.8579,  0.5059,  1.0243],\n",
      "        [ 1.4323,  0.2217,  0.8599,  ...,  0.4827,  0.8459,  1.3038]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(max_length))\n",
    "print(pos_embeddings.shape)\n",
    "print(pos_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aed0d9",
   "metadata": {},
   "source": [
    "The `context_length` is a variable that represents the supported input size of the LLM. Here, we choose it similar to the\n",
    "maximum length of the input text. In practice, input text can be longer than the supported context length, in which case we have to truncate the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d62459",
   "metadata": {},
   "source": [
    "- To create the input embeddings used in an LLM, we simply add the token and the positional embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ceed96ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n",
      "tensor([[[-0.1390,  0.6390,  1.3222,  ...,  0.6350, -2.3747,  0.9599],\n",
      "         [ 0.6543,  0.8614,  0.4532,  ...,  0.0369, -1.4310,  0.0136],\n",
      "         [ 0.3299, -1.4393,  0.9953,  ...,  1.8197,  2.8795,  0.9715],\n",
      "         [ 2.3781,  1.0874,  2.4790,  ...,  0.0283,  0.0999,  1.6521]],\n",
      "\n",
      "        [[ 0.9158,  1.2520, -0.9214,  ...,  0.9341,  0.3572,  0.7624],\n",
      "         [-1.6560,  0.4164,  0.3375,  ...,  0.6591, -0.5815,  1.8070],\n",
      "         [ 2.5653, -2.0329,  0.1851,  ...,  0.4738, -0.4297,  2.4721],\n",
      "         [ 2.3971,  1.5190, -0.7608,  ...,  1.6290,  2.4256,  1.7007]],\n",
      "\n",
      "        [[-1.4016,  0.1724,  0.0297,  ...,  0.2302, -0.4470,  1.8471],\n",
      "         [ 1.0107,  1.1125,  2.0109,  ...,  1.0020,  0.1778,  1.5185],\n",
      "         [ 0.6601, -3.1482,  0.9016,  ...,  3.0402,  2.3289,  0.6608],\n",
      "         [ 1.8590,  0.1569,  1.4285,  ..., -0.0382,  2.1524,  2.1511]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.2458,  0.4762, -2.7803,  ...,  0.0701,  0.5877,  2.7428],\n",
      "         [-0.1923, -0.3157, -0.5976,  ..., -1.6210, -1.3633,  2.1727],\n",
      "         [ 1.1895, -0.8517,  0.5246,  ...,  0.2246, -0.5964,  2.6535],\n",
      "         [ 1.8000,  0.0516, -0.5188,  ...,  1.1875,  1.3487,  1.2464]],\n",
      "\n",
      "        [[-0.7582,  0.1306,  1.5807,  ...,  1.4134, -0.9764,  2.6303],\n",
      "         [ 0.6923, -1.1027,  1.1604,  ..., -0.3153, -2.0713,  3.0734],\n",
      "         [-0.3767, -0.6840,  1.6845,  ...,  2.7957, -1.3994, -0.1573],\n",
      "         [ 1.6325, -0.5389, -0.6571,  ...,  0.4522,  0.4803,  1.1640]],\n",
      "\n",
      "        [[-1.5876,  0.2158,  1.2213,  ...,  2.9723, -2.4064, -0.0771],\n",
      "         [ 0.1430, -0.0470, -0.3108,  ..., -1.4166, -0.7345,  1.0852],\n",
      "         [ 1.1838, -0.4863,  2.3988,  ...,  2.3821,  0.7089,  0.7241],\n",
      "         [ 2.5598,  0.1134,  0.6404,  ...,  0.9886, -0.9679,  1.2338]]],\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)\n",
    "print(input_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6151ec",
   "metadata": {},
   "source": [
    "- In the initial phase of the input processing workflow, the input text is segmented into separate tokens\n",
    "\n",
    "- Following this segmentation, these tokens are transformed into token IDs based on a predefined vocabulary:\n",
    "\n",
    "![Alt text](../../assests/pos-embedding.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a55cff",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- LLMs require textual data to be converted into numerical vectors, known as embeddings since they can't process raw text. Embeddings transform discrete data (like words or images) into continuous vector spaces, making them compatible with neural network operations.\n",
    "\n",
    "\n",
    "- As the first step, raw text is broken into tokens, which can be words or characters. Then, the tokens are converted into integer representations, termed token IDs.\n",
    "\n",
    "\n",
    "- Special tokens, such as `<|unk|>` and `<|endoftext|>`, can be added to enhance the model's understanding and handle various contexts, such as unknown words or marking the boundary between unrelated texts.\n",
    "\n",
    "\n",
    "- The `byte pair encoding (BPE)` tokenizer used for LLMs like `GPT-2` and `GPT-3` can efficiently handle unknown words by breaking them down into subword units or individual characters.\n",
    "\n",
    "\n",
    "- We use a `sliding window` approach on tokenized data to generate input-target pairs for LLM training.\n",
    "\n",
    "\n",
    "- Embedding layers in PyTorch function as a lookup operation, retrieving vectors corresponding to token IDs. The resulting embedding vectors provide continuous representations of tokens, which is crucial for training deep learning models like LLMs.\n",
    "\n",
    "\n",
    "- While token embeddings provide consistent vector representations for each token, they lack a sense of the token's position in a sequence. To rectify this, two main types of positional embeddings exist: absolute and relative. OpenAI's GPT models utilize absolute positional embeddings that are added to the token embedding vectors and are optimized during the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bada249",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
