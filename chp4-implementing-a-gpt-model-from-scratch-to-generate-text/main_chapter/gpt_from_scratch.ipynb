{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b4add58",
   "metadata": {},
   "source": [
    "# Implementing a GPT model from Scratch To Generate Text\n",
    "\n",
    "This section covers:\n",
    "\n",
    "- Coding a GPT-like large language model (LLM) that can be trained to generate human-like text.\n",
    "\n",
    "- Normalizing layer activations to stabilize neural network training\n",
    "\n",
    "- Adding shortcut connections in deep neural networks to train models more effectively.\n",
    "\n",
    "- Implementing transformer blocks to create GPT models of various sizes.\n",
    "\n",
    "- Computing the number of parameters and storage requirements of GPT models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fca367a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.6\n",
      "torch version: 2.0.1\n",
      "tiktoken version: 0.11.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "print(\"matplotlib version:\", version(\"matplotlib\"))\n",
    "print(\"torch version:\", version(\"torch\"))\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed2958",
   "metadata": {},
   "source": [
    "![Alt text](../../assests/figure41.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9918751e",
   "metadata": {},
   "source": [
    "## Coding an LLM architecture\n",
    "\n",
    "LLMs, such as GPT (Generative Pretrained Transformer), are large deep neural network architectures designed to generate new text one word (or token) at a time. \n",
    "\n",
    "![Alt text](../../assests/figure42.png)\n",
    "\n",
    "- We've covered `Input tokenization and embedding`, `masked multi-head attention` module.\n",
    "\n",
    "- This section focuses on implementing the core structure of the GPT model, including its transformer blocks.\n",
    "- Therefore, these LLMs are often referred to as `\"decoder-like\"` LLMs\n",
    "- Language models are Unsupervised Multitask Learners.\n",
    "- We are scaling up to the size of a small GPT-2 model, specifically the smallest version with `124` million parameters.\n",
    "- In the context of deep learning and LLMs like GPT, the term \"parameters\" refers to the trainable weights of the model. These weights are essentially the internal variables of the model that are adjusted and optimized during the training process to minimize a specific loss function. This optimization allows the model to learn from the training data.\n",
    "- Compared to conventional deep learning models, LLMs are larger, mainly due to their vast number of parameters, not the amount of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7affaa6",
   "metadata": {},
   "source": [
    "- Configuration details for the `124 million` parameter GPT-2 model include:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7123d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eee003",
   "metadata": {},
   "source": [
    "We use short variable names to avoid long lines of code later\n",
    "- `\"vocab_size\"` indicates a vocabulary size of `50,257` words, supported by the `BPE` tokenizer discussed in Chapter 2.\n",
    "\n",
    "- `\"context_length\"` represents the model's maximum input token count, as enabled by positional embeddings covered in Chapter 2\n",
    "\n",
    "- `\"emb_dim\"` is the embedding size for token inputs, converting each input token into a `768`-dimensional vector\n",
    "\n",
    "- `\"n_heads\"` is the number of attention heads in the `multi-head attention` mechanism implemented in Chapter 3\n",
    "  \n",
    "- `\"n_layers\"` is the number of transformer blocks within the model, which we'll implement in upcoming sections\n",
    "\n",
    "- `\"drop_rate\"` is the dropout mechanism's intensity, discussed in Chapter 3; `0.1` means dropping `10%` of hidden units during training to mitigate overfitting\n",
    "\n",
    "- `\"qkv_bias\"` decides if the Linear layers in the multi-head attention mechanism (from Chapter 3) should include a bias vector when computing `query (Q)`, `key (K)`, and `value (V)` tensors; we'll disable this option, which is standard practice in modern LLMs; however, we'll revisit this later when loading pretrained GPT-2 weights from OpenAI into our reimplementation in chapter 5\n",
    "\n",
    "\n",
    "\n",
    "Using the configuration above, we will start this section by implementing a `GPT placeholder` architecture (`DummyGPTModel`) in this section, as shown in the figure below. This will provide us with a big-picture view of how everything fits together and what other components we need to code in the upcoming sections to assemble the full GPT model architecture.\n",
    "\n",
    "\n",
    "![Alt text](../../assests/figure43.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb5236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A placeholder GPT model architecture class\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, config: dict):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(config[\"vocab_size\"], config[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(config[\"context_length\"], config[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(config[\"drop_rate\"])\n",
    "        \n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(config) for _ in range(config[\"n_layers\"])]\n",
    "        )\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(config[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            config[\"emb_dim\"], config[\"vocab_size\"], bias=False\n",
    "        )\n",
    "        \n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input\n",
    "        return x\n",
    "    \n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cae92e",
   "metadata": {},
   "source": [
    "The `DummyGPTModel` class above defines a simplified version of a GPT-like model using PyTorch's neural network module (nn.Module). The model architecture in the `DummyGPTModel` class consists of token and positional embeddings, dropout, a series of transformer blocks `(DummyTransformerBlock)`, a final layer normalization `(DummyLayerNorm)`, and a linear output layer `(out_head)`. \n",
    "\n",
    "- The configuration is passed in via a Python dictionary, for instance, the `GPT_CONFIG_124M` dictionary we created earlier.\n",
    "\n",
    "- The `forward` method describes the data flow through the model; it computes `token` and `positional` embeddings for the input indices, applies `dropout`, processes the data through the `transformer` blocks, applies normalization, and finally produces logits with the linear output layer.\n",
    "\n",
    "- The code above is already functional, as we will see later in this section after we prepare the input layer. However, the placeholders `(DummyLayerNorm and DummyTransformerBlock)` for the transformer block and layer normalization, which we will develop in later sections.\n",
    "\n",
    "![Alt text](../../assests/figure44.png)\n",
    "\n",
    "Next, we will prepare the input data and initialize a new GPT model to illustrate its usage. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4bccc",
   "metadata": {},
   "source": [
    "- To implement the step in the figure above, we tokenize a batch consisting of two text inputs for the GPT model using the `tiktoken` tokenizer introduced in chap.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "\n",
    "text1 = \"Every effort moves you\"\n",
    "text2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(text1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(text2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "628de503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f13968",
   "metadata": {},
   "source": [
    "- The output above are the resulting token IDs for the two texts. The first row corresponds to the first text, and the second row corresponds to the second text.\n",
    "\n",
    "- Next, we initialize a new `124 million` parameter `DummyGPTModel` instance and feed it the tokenized `batch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9347b66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6755, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eb6770",
   "metadata": {},
   "source": [
    "- The model outputs above, are commonly referred to as logits.\n",
    "\n",
    "- The output tensor has two rows corresponding to the two text samples. Each text sample consists of 4 tokens; each token is a `50,257`-dimensional vector, which matches the size of the tokenizer's vocabulary.\n",
    "\n",
    "- The embedding has `50,257` dimensions because each of these dimensions refers to a unique token in the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df36b076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyGPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): DummyTransformerBlock()\n",
       "    (1): DummyTransformerBlock()\n",
       "    (2): DummyTransformerBlock()\n",
       "    (3): DummyTransformerBlock()\n",
       "    (4): DummyTransformerBlock()\n",
       "    (5): DummyTransformerBlock()\n",
       "    (6): DummyTransformerBlock()\n",
       "    (7): DummyTransformerBlock()\n",
       "    (8): DummyTransformerBlock()\n",
       "    (9): DummyTransformerBlock()\n",
       "    (10): DummyTransformerBlock()\n",
       "    (11): DummyTransformerBlock()\n",
       "  )\n",
       "  (final_norm): DummyLayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "905898b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: tok_emb.weight, Shape: torch.Size([50257, 768])\n",
      "Weights: \n",
      "tensor([[ 3.3737e-01, -1.7778e-01, -3.0353e-01,  ..., -3.1813e-01,\n",
      "         -1.3936e+00,  5.2262e-01],\n",
      "        [ 2.5787e-01,  3.4197e-01, -8.1678e-01,  ..., -4.0981e-01,\n",
      "          4.9785e-01, -3.7207e-01],\n",
      "        [ 7.9574e-01,  5.3501e-01,  9.4275e-01,  ..., -1.0749e+00,\n",
      "          9.5492e-02, -1.4138e+00],\n",
      "        ...,\n",
      "        [-7.1278e-01, -5.0190e-01,  1.4119e+00,  ..., -1.4979e-01,\n",
      "         -4.8977e-01, -1.0620e+00],\n",
      "        [ 2.0646e+00,  1.1190e+00,  3.8486e-01,  ..., -7.2015e-01,\n",
      "         -5.5703e-01,  9.8639e-01],\n",
      "        [ 1.1364e-03, -7.5320e-01, -1.7924e-01,  ..., -3.2443e-01,\n",
      "          2.6055e-01,  5.8885e-01]])\n",
      "Layer: pos_emb.weight, Shape: torch.Size([1024, 768])\n",
      "Weights: \n",
      "tensor([[ 0.8769,  0.2550,  0.8441,  ..., -1.0354,  1.3085,  1.7957],\n",
      "        [-1.0029,  0.0995,  1.2459,  ...,  1.5453, -0.1126, -1.5197],\n",
      "        [ 1.3317,  0.7561,  0.9077,  ...,  0.0830,  1.8336, -2.2225],\n",
      "        ...,\n",
      "        [-0.1055, -1.1941, -1.1472,  ..., -1.4544,  0.2918, -0.5483],\n",
      "        [ 0.2218, -0.3332, -1.3375,  ..., -0.4280, -0.0806,  1.7783],\n",
      "        [ 1.1077,  0.0933,  0.8395,  ..., -1.4756,  1.1813,  2.3671]])\n",
      "Layer: out_head.weight, Shape: torch.Size([50257, 768])\n",
      "Weights: \n",
      "tensor([[ 0.0266,  0.0049, -0.0182,  ...,  0.0070, -0.0124, -0.0275],\n",
      "        [ 0.0156, -0.0022, -0.0125,  ..., -0.0274,  0.0311,  0.0285],\n",
      "        [ 0.0044, -0.0063, -0.0033,  ..., -0.0279, -0.0054, -0.0342],\n",
      "        ...,\n",
      "        [-0.0277, -0.0312,  0.0010,  ..., -0.0004,  0.0167, -0.0232],\n",
      "        [-0.0295, -0.0061, -0.0285,  ..., -0.0118, -0.0086, -0.0206],\n",
      "        [-0.0318,  0.0247,  0.0175,  ..., -0.0301, -0.0244,  0.0342]])\n"
     ]
    }
   ],
   "source": [
    "# Access model parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name}, Shape: {param.shape}\")\n",
    "    print(f\"Weights: \\n{param.data}\") # .data to get the tensor values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec40ee",
   "metadata": {},
   "source": [
    "## Normalizing activations with layer normalization\n",
    "\n",
    "- Training deep neural networks with many layers can sometimes prove challenging due to issues like `vanishing` or `exploding` gradients. These issues lead to unstable training dynamics and make it difficult for the network to effectively adjust its weights, which means the learning process struggles to find a set of parameters (weights) for the neural network that minimizes the `loss function`. In other words, the network has difficulty learning the underlying patterns in the data to a degree that would allow it to make accurate predictions or decisions. \n",
    "\n",
    "\n",
    "- We will implement a  `layer normalization` to improve the stability and efficiency of neural network training.\n",
    "- The main idea behind `layer normalization` is to adjust the activations (outputs) of a neural network layer to have a mean of `0` and a variance of `1`, also know as `unit variance`.\n",
    "- This adjustment speeds up the convergence to effective weights and ensures consistent, reliable training. \n",
    "- Layer normalization is applied both before and after the multi-head attention module within the transformer block, which we will implement later.\n",
    "- It's also applied before the final output layer.\n",
    "\n",
    "\n",
    "Here is a visual overview of how layer normalization functions.\n",
    "\n",
    "![Alt text](../../assests/figure45.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8659d262",
   "metadata": {},
   "source": [
    "- Let's see how layer normalization works by passing a small input sample through a simple neural network layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bec6c9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "# create 2 training examples with 5 dimensions (features) each\n",
    "batch_example = torch.randn(2, 5)\n",
    "\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fcde96",
   "metadata": {},
   "source": [
    "- The first row of the output above lists the layer outputs for the first input and the second row lists the layer outputs for the second row:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea8f8c8",
   "metadata": {},
   "source": [
    "- The neural network layer above consists of a `Linear` layer followed by a non-linear activation function, `ReLU` (short for Rectified Linear Unit), which is a standard activation function in neural networks. \n",
    "\n",
    "- `ReLU` simply thresholds negative inputs to `0`, ensuring that a layer outputs only positive values, which explains why the resulting layer output does not contain any negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6])\n"
     ]
    }
   ],
   "source": [
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa2b6b",
   "metadata": {},
   "source": [
    "Let's compute the mean and variance for each of the 2 inputs above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=1, keepdim=True)\n",
    "var = out.var(dim=1, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0fc2b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.shape, var.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d040d7d",
   "metadata": {},
   "source": [
    "- The first row in the `mean` tesnor contains the `mean` value for the first input row, and the second output row contains the `mean` for the second input row.\n",
    "\n",
    "- Using `keepdim=True` in operations like mean or variance calculation ensures that the output tensor retains the same number of dimensions as the input tensor, even though the operation reduces the tensor along the dimension specified via `dim`. For instance, without `Keepdim=True`, the returned mean tensor would be a 2-dimensional vector of `[0.1324,\n",
    "0.2170]` instead of a 2Ã—1-dimensional matrix `[[0.1324], [0.2170]]`.\n",
    "\n",
    "- The `dim` parameter specifies the dimension along which the calculation of the statistic (here, mean and variance) should be performed in a tensor.\n",
    "\n",
    "![Alt text](../../assests/figure46.png)\n",
    "\n",
    "\n",
    "From the figure above, for a `2D` tensor (like a matrix), using `dim=-1` for operations such as mean and variance calculation is the same as using `dim=1`. This is beacuase `-1` refers to the tensor's last dimension, which corresponds to the columns in a `2D` tensor. \n",
    "\n",
    "- Later, when adding layer normalization to the GPT model, which produces `3D` tensors with shape `[batch_size, num_tokens, embedding_size]`, we can still use `dim=-1` for normalization across the last dimension, avoiding a change from `dim=1` to `dim=2`.\n",
    "\n",
    "- Let us apply layer normalization to the layer outputs we obtained earlier. The operation consists of substracting the mean and dividing by the `square-root` of the variance (also known as `standard deviation`). This centers the inputs to have a mean of `0` and a variance of `1` across the column (feature) dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb59dfba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[2.9802e-08],\n",
      "        [3.9736e-08]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.],\n",
      "        [1.]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a797b0",
   "metadata": {},
   "source": [
    "- The normalized layer outputs above contain negative values, have zero mean and a variance of 1.\n",
    "\n",
    "- To improve readability, we can also turn off the scientific notation when printing tensor values by setting `sci_mode` to False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d75eb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    0.0000],\n",
      "        [    0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.],\n",
      "        [1.]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307a887",
   "metadata": {},
   "source": [
    "- Above we normalized the features of each input.\n",
    "- Now, using the same idea, we can implement a `LayerNorm` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d00a524",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d602f09",
   "metadata": {},
   "source": [
    "- This specific implementation of `layer Normalization` operates on the last dimension of the input tensor `x`, which represents the embedding dimension `(emb_dim)`. The variable `eps` is a small constant `(epsilon)` added to the variance to prevent division by zero during normalization.\n",
    "\n",
    "**Scale and shift**\n",
    "\n",
    "- Note that in addition to performing the normalization by subtracting the mean and dividing by the variance, we added two trainable parameters, a `scale` and a `shift` parameter.\n",
    "\n",
    "- The initial `scale` (multiplying by 1) and `shift` (adding 0) values don't have any effect; however, `scale` and `shift` are trainable parameters that the LLM automatically adjusts during training if it is determined that doing so would improve the model's performance on its training task.\n",
    "\n",
    "- This allows the model to learn appropriate scaling and shifting that best suit the data it is processing.\n",
    "\n",
    "- Note that we also add a smaller value `(eps)` before computing the square-root of the variance; this is to avoid division-by-zero errors if the variance is `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0f9eae",
   "metadata": {},
   "source": [
    "**BIASED VARIANCE**\n",
    "\n",
    "- In the variance calculation above, setting `unbiased=False` means using the formula:\n",
    "\n",
    "$$\\sigma^2 = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2$$\n",
    "\n",
    "to compute the variance, where $n$ is the sample size (here, the number of features or columns). This formula does not include Bessel's correction (which uses $n-1$ in the denominator), thus providing a **biased estimate** of the population variance.\n",
    "\n",
    "- For LLMs, where the embedding dimension `n` is very large, the difference between using `n` and `n-1` is negligible.\n",
    "\n",
    "- However, `GPT-2` was trained with a biased variance in the normalization layers, which is why we also adopted this setting for compatibility reasons with the pretrained weights that we will load in later section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad054a8",
   "metadata": {},
   "source": [
    "- Let's now try the LayerNorm module in practice and apply it to the batch input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7185745a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[    -0.0000],\n",
      "        [     0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a4066",
   "metadata": {},
   "source": [
    "![Alt text](../../assests/figure47.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00734aec",
   "metadata": {},
   "source": [
    "**LAYER NORMALIZATION VERSUS BATCH NORMALIZATION**\n",
    "\n",
    "\n",
    "If you are familiar with batch normalization, a common and traditional normalization method for neural networks, you may wonder how it compares to layer normalization. Unlike batch normalization, which normalizes across the batch dimension, layer normalization normalizes across the feature dimension. LLMs often require significant computational resources, and the available hardware or the specific use case can dictate the batch size during training or inference. Since layer\n",
    "normalization normalizes each input independently of the batch size, it offers more flexibility and stability in these scenarios. This is particularly beneficial for `distributed training` or when deploying models in environments where resources are constrained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02684b8",
   "metadata": {},
   "source": [
    "## Implementing a feed forward network with GELU activations\n",
    "\n",
    "\n",
    "- In this section, we implement a small neural network submodule that is used as part of the transformer block in LLMs.\n",
    "- We start with the activation function.\n",
    "- In deep learning, `ReLU` (Rectified Linear Unit) activation functions are commonly used due to their simplicity and effectiveness in various neural network architecture.\n",
    "- In LLMs, various other types of activation functions are used beyond the traditional ReLU; two notable examples are `GELU` (Gaussian Error Linear Unit) and `SwiGLU` (Swish-Gated Linear Unit).\n",
    "- `GELU` and `SwiGLU` are more complex, smooth activation functions incorporating Gaussian and sigmoid-gated linear units, respectively, offering better performance for deep learning models, unlike the simpler, piecewise linear function of `ReLU`.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0e97a",
   "metadata": {},
   "source": [
    "### **GELU**\n",
    "\n",
    "The **GELU** (Gaussian Error Linear Unit) activation function is defined as:\n",
    "\n",
    "$$\\text{GELU}(x) = x \\cdot \\Phi(x)$$\n",
    "\n",
    "where $\\Phi(x)$ is the cumulative distribution function of the standard normal distribution.\n",
    "\n",
    "It can be approximated by:\n",
    "\n",
    "$$\\text{GELU}(x) \\approx 0.5x \\left(1 + \\tanh\\left(\\sqrt{\\frac{2}{\\pi}}(x + 0.044715x^3)\\right)\\right)$$\n",
    "\n",
    "**Key property:** It smoothly weights inputs by their value, using a probabilistic approach (rather than a hard gate like ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An implementation of the GELU activation function\n",
    "\n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efdca32",
   "metadata": {},
   "source": [
    "- To get an idea of what this `GELU` function looks like and how it compares to the `ReLU` function, let's plot these functions side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14e664cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc1fb0a",
   "metadata": {},
   "source": [
    "- As seen from the plot above, `ReLU` is a piecewise linear function that outputs the input directly if it is positive; otherwise, it outputs zero.\n",
    "\n",
    "- `ReLU` has a sharp corner at zero, which can sometimes make optimization harder, especially in networks that are very deep or have complex architectures.\n",
    "\n",
    "- The smooothness of `GELU` can lead to better optimization properties during training, as it allows for more naunced adjustments to the model's parameters.\n",
    "\n",
    "- `GELU` is a smooth, non-linear function that approximates `ReLU` but with a non-zero gradient for negative values (except at approximately `-0.75`)\n",
    "\n",
    "- `GELU` allows for a small, non-zero output for negative values. This means that during the training process, neurons that receive negative input can still contribute to the learning process, albeit to a lesser extent than positive inputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27f11a",
   "metadata": {},
   "source": [
    "- Next, let's implement the small neural network module, `FeedForward`, that we will be using in the `LLM's` transformer block later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A feed. forward neural network\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(config[\"emb_dim\"], 4 * config[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * config[\"emb_dim\"], config[\"emb_dim\"]),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a453e9",
   "metadata": {},
   "source": [
    "- As seen in the preceding code, the `FeedForward` module is a small neural network consisting of two `Linear` layers and a `GELU` activation function. In the 124 million parameter GPT model, it receives the input batches with tokens that have an embedding size of `768` each via the `GPT_CONFIG_124M` dictionary where `GPT_CONFIG_124M[\"emb_dim\"] = 768`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0082b801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15309c57",
   "metadata": {},
   "source": [
    "![Alt text](../../assests/figure49.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e093ffe9",
   "metadata": {},
   "source": [
    "- The above image provides a visual overview of the connections between the layers of the feed forward neural network. It is important to note that this neural network can accommodate variable batch sizes and numbers of tokens in the input. However, the embedding size for each token is determined and fixed when initializing the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "870e62e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "\n",
    "# input shape: [batch_size, num_token, emb_size]\n",
    "x = torch.rand(2, 3, 768) \n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d22c445",
   "metadata": {},
   "source": [
    "- from the above output, the shape of the output tensor is the same as that of the input tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6c0eb2",
   "metadata": {},
   "source": [
    "The `FeedForward` module we implemented in this section plays a crucial role in enhancing the model's ability to learn from and generalize the data. Although the input and output dimensions of this module are the same, it internally expands the embedding dimension into a higher-dimensional space through the first linear layer as illustrated in the figure below. \n",
    "\n",
    "![Alt text](../../assests/figure410.png)\n",
    "\n",
    "`An illustration of the expansion and contraction of the layer outputs in the feed forward neural\n",
    "network. First, the inputs expand by a factor of 4 from 768 to 3072 values. Then, the second layer compresses\n",
    "the 3072 values back into a 768-dimensional representation.`\n",
    "\n",
    "This expansion is followed by a non-linear `GELU` activation, and then a contraction back to the original dimension with the second linear transformation. Such a design allows for the exploration of a richer representation space.\n",
    "\n",
    "The uniformity in input and output dimensions simplifies the architecture by enabling the stacking of multiple layers, without the need to adjust dimensions between them, thus making the model more scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9022d45b",
   "metadata": {},
   "source": [
    "![Alt text](../../assests/figure411.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548b3670",
   "metadata": {},
   "source": [
    "## Adding shortcut connections\n",
    "\n",
    "- Next, let's talk about the concept behind shortcut connections, also called `skip` or `residual` connections\n",
    "\n",
    "- Originally, shortcut connections were proposed in deep networks for computer vision (residual networks) to mitigate vanishing gradient problems.\n",
    "\n",
    "- The vanishing gradient problem refers to the issue where gradients (which guide weight updates during training) become progressively smaller as they propagate backward through the layers, making it difficult to effectively train earlier layers.\n",
    "\n",
    "- A shortcut connection creates an alternative shorter path for the gradient to flow through the network\n",
    "\n",
    "- This is achieved by adding the output of one layer to the output of a later layer, usually skipping one or more layers in between\n",
    "\n",
    "- Let's illustrate this idea with a small example network:\n",
    "\n",
    "\n",
    "![Alt text](../../assests/figure412.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b59d5fe",
   "metadata": {},
   "source": [
    "### **Shortcut Connection (Skip Connection)**\n",
    "\n",
    "#### **Intuition**\n",
    "Shortcut connections skip one or more layers, allowing the gradient to flow directly backwards during training. This mitigates the **vanishing gradient problem** in deep networks, enabling the training of very deep architectures (e.g., ResNet).\n",
    "\n",
    "#### **Math (ResNet Style)**\n",
    "For a layer with input $( x )$, the output $( y )$ with a shortcut is:\n",
    "\n",
    "$$y = F(x, \\{W_i\\}) + x$$\n",
    "\n",
    "where $( F(x, {W_i}) )$ is the transformation (e.g., convolutional layers) and $( x )$ is the identity shortcut.\n",
    "\n",
    "#### **Code Example (PyTorch)**\n",
    "```python\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.conv1(x))\n",
    "        out = self.conv2(out)\n",
    "        out += residual  # Shortcut connection\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "```\n",
    "\n",
    "#### **Why it works**\n",
    "- **Eases optimization**: The network can learn identity functions easily.\n",
    "- **Improves gradient flow**: Gradients can propagate directly through shortcuts, avoiding degradation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cce6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8f3a1f",
   "metadata": {},
   "source": [
    "- The code above implements a deep neural network with `5` layers, each consisting of a `Linear` layer and a `GELU` activation function. In the forward pass, we iteratively pass the input through the layers and optionally add the shortcut connections if the `self.use_shortcut` attribute is set to `True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270139fc",
   "metadata": {},
   "source": [
    "The code below computes the loss function, which quantifies how close the model output and a specified target are. Then, when calling `loss.backward()`, PyTorch computes the loss gradient for each layer in the model. We can iterate through the weight parameters via `model.named_parameters()`. \n",
    "\n",
    "- Next, we implement a function that computes the gradients in the model's backward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e925d7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "    \n",
    "    # Calculate loss based on how close the target and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d2e021",
   "metadata": {},
   "source": [
    "Let' use this code to initialize a neural network without `shortcut connections`. Here, each layer will be initialized such that it accepts an example with `3` input values and returns `3` output values. The last layer returns a single output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4968e043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False,\n",
    ")\n",
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05035bdf",
   "metadata": {},
   "source": [
    "As seen from the output of above, the gradients become smaller as we progress from the last layer `(layers.4)` to the first layer `(layers.0)`, which is a phenomenon called the `vanishing gradient` problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fec7c9b",
   "metadata": {},
   "source": [
    "- Next, we print the gradient values with shortcut connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6ca6394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/torch/autograd/__init__.py:200: UserWarning: Error detected in AddmmBackward0. Traceback of forward call that caused the error:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.11/3.11.13/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/9z/v7273dts7dd75tz0ppy1qfdr0000gn/T/ipykernel_72072/1990862935.py\", line 6, in <module>\n",
      "    print_gradients(model_with_shortcut, sample_input)\n",
      "  File \"/var/folders/9z/v7273dts7dd75tz0ppy1qfdr0000gn/T/ipykernel_72072/2784095629.py\", line 3, in print_gradients\n",
      "    output = model(x)\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/var/folders/9z/v7273dts7dd75tz0ppy1qfdr0000gn/T/ipykernel_72072/368581698.py\", line 16, in forward\n",
      "    layer_output = layer(x)\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/torch/nn/modules/container.py\", line 217, in forward\n",
      "    input = module(input)\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/user/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      " (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/autograd/python_anomaly_mode.cpp:119.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 3]], which is output 0 of AddBackward0, is at version 4; expected version 3 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m model_with_shortcut = ExampleDeepNeuralNetwork(\n\u001b[32m      3\u001b[39m     layer_sizes, use_shortcut=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m      4\u001b[39m )\n\u001b[32m      5\u001b[39m torch.autograd.set_detect_anomaly(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mprint_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_with_shortcut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mprint_gradients\u001b[39m\u001b[34m(model, x)\u001b[39m\n\u001b[32m      9\u001b[39m loss = loss(output, target)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Backward pass to calculate the gradients\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model.named_parameters():\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mweight\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m name:\n\u001b[32m     16\u001b[39m         \u001b[38;5;66;03m# Print the mean absolute gradient of the weights\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    477\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    479\u001b[39m         Tensor.backward,\n\u001b[32m    480\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    485\u001b[39m         inputs=inputs,\n\u001b[32m    486\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Building-LLMs-from-scratch/venv/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    195\u001b[39m     retain_graph = create_graph\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 3]], which is output 0 of AddBackward0, is at version 4; expected version 3 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dac144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18be38b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852126dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151710b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21703cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca56ede7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708fdbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8c3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b7c7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb2e924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93d6895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c411866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad64a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d05b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7861ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d916fdc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6cd453",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5828415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a8696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae9cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa064a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad569a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9e8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
